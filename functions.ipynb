{"cells":[{"block_group":"c09b2fc45e624ad2a7854fc00fe13d06","cell_type":"code","execution_count":null,"metadata":{"cell_id":"6c959ff5393440b39a45be899b853809","deepnote_block_group":"c09b2fc45e624ad2a7854fc00fe13d06","deepnote_cell_type":"code","deepnote_sorting_key":"0","deepnote_source":"# Load json to parse JSON text for functions module\nimport json\n\n# Load sys so Python can locate files in list of directories\nimport sys\n\n# Load os to get the current directory path\nimport os\n\n# load inspect to examine Python objects\nimport inspect\n\n# Load geopandas library to work with geoJSON files.\nimport geopandas as gpd\n\n# Load pandas library for data manipulation and analysis.\nimport pandas as pd\n\n# Load matplotlib library for data visualization.\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\n\n# Load folium to visualize geospatial data.\nimport folium\n\n# Load cmocean for colormaps.\nimport cmocean.cm as cmo\n\n# Load datetime to manipulate dates and times.\nfrom datetime import datetime\n\n# Load requests to conduct HTTP requests to an API.\nimport requests\n\n# Load time so we can time and optimize queries.\nimport time\n\n# Load Point to use in coordinate mapping.\nfrom shapely.geometry import Point\n\n\n# for cloropleth map function\nfrom branca.element import MacroElement\n\n# for cloropleth map function\nfrom jinja2 import Template\n\n#______________________________________________________________________________\n\ndef summarize_dataframe(df):\n    \"\"\"\n    Summarizes a DataFrame/GeoDataFrame with column-level statistics.\n    Args:\n        df: a pandas DataFrame or geopandas GeoDataFrame to summarize\n    Returns:\n        DataFrame with summary statistics for each column:\n            Type: column data type\n            Missing: count of missing values\n            Missing %: percent of missing values\n            Unique: count of unique values\n            min, max, mean: minimum, maximum, and mean (numeric columns only)\n    Raises:\n        AttributeError: If df input is not a DataFrame-like object\n        ZeroDivisionError: If DataFrame is empty\n    \"\"\"\n    summary = {\n        col: {\n            'Type': df[col].dtype,\n            'Missing': df[col].isnull().sum(),\n            'Missing %': round(df[col].isnull().sum() / len(df) * 100, 2),\n            'Unique': df[col].nunique()\n        }\n        for col in df.columns\n    }\n    \n    # Transpose summary so each row represents one column from df.\n    summary_df = pd.DataFrame(summary).T\n\n    # Grab numeric columns only (geometry is excluded automatically).\n    numeric_cols = df.select_dtypes(include='number')\n\n    # Compute summary statistics for numeric columns.\n    if not numeric_cols.empty:\n        summary_stats = numeric_cols.agg(['min', 'max', 'mean']).T.round(2)\n        summary_df = summary_df.join(summary_stats)\n\n    return summary_df\n\n#______________________________________________________________________________\n\n#______________________________________________________________________________\n\ndef group_and_sum(df, column):\n    \"\"\"\n    Groups a DataFrame/GeoDataFrame by a specified column,\n    and sums the numeric columns.\n    Args:\n        df: a pandas DataFrame or geopandas GeoDataFrame\n        column: Column name to group by (string)\n    Returns:\n        pandas DataFrame with grouped data and summed numeric values\n    Raises:\n        ValueError: If df contains no numeric columns to sum\n    \"\"\"\n\n    # Check for numeric columns before grouping.\n    numeric_cols = df.select_dtypes(include='number').columns\n    numeric_cols = [col for col in numeric_cols if col != column]\n\n    if len(numeric_cols) == 0:\n        raise ValueError(\"DataFrame contains no numeric columns to sum\")\n\n    return df.groupby(column).sum()\n\n#______________________________________________________________________________\n\n#______________________________________________________________________________\n\ndef min_max(df, column):\n    \"\"\"\n    Computes the minimum and maximum values of a column.\n    Args:\n        df: a pandas DataFrame\n        column: Column name to compute min/max for (string)\n    Returns:\n        (min_value, max_value) for the specified column (tuple)\n    Raises:\n        KeyError: If the column does not exist in the DataFrame.\n    \"\"\"\n    return df[column].min(), df[column].max()\n    \n#______________________________________________________________________________\n\n#______________________________________________________________________________\n\ndef df_to_geodataframe(df, lon_col, lat_col, crs = \"EPSG:4326\"):\n    \"\"\"\n    Convert a pandas DataFrame with lon/lat columns into a GeoDataFrame.\n    Ensures longitude and latitude columns to numeric values, drops\n    rows with missing coordinates, and creates Point geometry objects.\n    Args:\n        df: pandas DataFrame\n        lon_col: Longitude column name (string)\n        lat_col: Latitude column name (string)\n        crs: Coordinate reference system (string, default: \"EPSG:4326\")\n    Returns:\n        geopandas.GeoDataFrame with Points in specified CRS\n    \"\"\"\n\n    df = df.copy()\n\n    # Ensure latitude and longitude columns are numeric.\n    df[lat_col] = pd.to_numeric(df[lat_col], errors = \"coerce\")\n    df[lon_col] = pd.to_numeric(df[lon_col], errors = \"coerce\")\n\n    # Drop rows with missing data.\n    df = df.dropna(subset = [lon_col, lat_col])\n\n    # Create geometry object using Shapely Point.\n    df[\"geometry\"] = [Point(xy) for xy in zip(df[lon_col], df[lat_col])]\n\n    # Convert DataFrame to a GeoDataFrame.\n    gdf = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=crs)\n\n    return gdf\n\n#______________________________________________________________________________\n\n#______________________________________________________________________________\n\ndef create_map_orig(gdf, fields = None, title = None, color_code = None):\n    \"\"\"\n    Create an interactive folium map.\n    Centers the map of the gdf's center and handles coordinate \n    transformations. Optionally color-codes features by a specified column.\n    Args:\n        gdf: GeoDataFrame to visualize\n        fields: field names to display in the tooltip (list, default = None)\n        title: Name of map (string, default = None)\n        color_code: Column name for color coding features (string, \n        default = None)\n    Returns:\n        folium.Map object with the GeoDataFrame layer added\n    \"\"\"\n\n    # Make a copy to avoid modifying the original GeoDataFrame.\n    gdf = gdf.copy()\n    \n    # Convert datetime columns to strings for JSON serialization.\n    datetime_cols = gdf.select_dtypes(\n        include = ['datetime64', 'datetime']\n        ).columns\n    for col in datetime_cols:\n        gdf[col] = gdf[col].astype(str)\n\n    # Calculate center based on CRS.\n    # If already in geographic crs, then\n    # project crs temporarily for centroid calculation.\n    if gdf.crs and gdf.crs.is_geographic:\n        # Use the UTM zone 17N for Detroit area.\n        gdf_projected = gdf.to_crs(epsg = 32617)\n        # Calculate center and project back to geographic.\n        center = gdf_projected.geometry.centroid.to_crs(epsg = 4326)\n    else:\n        center = gdf.geometry.centroid.to_crs(epsg = 4326)\n\n    # Calculate center\n    lat = center.y.mean()\n    lon = center.x.mean()\n\n    # Convert the crs to latitude/longitude for folium mapping.\n    gdf = gdf.to_crs(epsg = 4326)\n\n    # Create a centered base map with zoom level of 11.\n    map = folium.Map(\n        location = [lat, lon],\n        zoom_start = 11\n        )\n\n    # Configure styling based on color_code parameter.\n    if color_code:\n        # Get unique values and generate colors dynamically.\n        unique_values = gdf[color_code].unique()\n        num_colors = len(unique_values)\n        # Choose colormap based on number of categories.\n        if num_colors <= 10:\n            cmap = plt.cm.get_cmap('tab10')\n        elif num_colors <= 20:\n            cmap = plt.cm.get_cmap('tab20')\n        else:\n            cmap = plt.cm.get_cmap('hsv')\n        # Generate colors.\n        colors = [mcolors.rgb2hex(\n            cmap(i / num_colors)\n            ) \n            for i in range(num_colors)\n            ]\n        # Create color map dictionary.\n        color_map = {val: colors[i] for i, val in enumerate(unique_values)}\n        # Define style function with color coding.\n        style_function = lambda x: {\n            \"fillColor\": color_map.get(x['properties'][color_code], 'gray'),\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.7\n        }\n\n    # If color code is not specified, use one color.  \n    else:\n        # Define style function with single color.\n        style_function = lambda x: {\n            \"fillColor\": \"blue\",\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.5\n        }\n    \n    # Add GeoJSON layer to map.\n    folium.GeoJson(\n        gdf,\n        name = title,\n        style_function = style_function,\n        tooltip = folium.GeoJsonTooltip(\n            fields = fields\n            ) \n            if fields \n            else None\n    ).add_to(map)\n    \n    return map\n\n#______________________________________________________________________________\n\n#______________________________________________________________________________\n\ndef create_map(gdf, fields = None, title = None, color_code = None):\n    \"\"\"\n    Create an interactive folium map from a GeoDataFrame.\n    Centers the map on the GeoDataFrame's centroid and uses a muted \n    cmocean color scheme for better visibility.\n    Args:\n        gdf: geopandas.GeoDataFrame to visualize\n        fields: Field names to display in tooltip (list, default = None)\n        title: Name of the map layer (string, default = None)\n        color_code: column name for color coding features \n        (string, default = None)\n    Returns:\n        folium.Map object with the GeoDataFrame layer added\n    \"\"\"\n\n    gdf = gdf.copy()\n    \n    # Convert datetime columns to strings for JSON serialization\n    datetime_cols = gdf.select_dtypes(\n        include = ['datetime64', 'datetime']\n        ).columns\n    for col in datetime_cols:\n        gdf[col] = gdf[col].astype(str)\n\n    # Calculate center based on CRS\n    # If already in geographic CRS, project temporarily for accurate centroid\n    if gdf.crs and gdf.crs.is_geographic:\n        # Use UTM zone 17N for Detroit area\n        gdf_projected = gdf.to_crs(epsg = 32617)\n        # Project back to EPSG:4326 immediately\n        center = gdf_projected.geometry.centroid.to_crs(epsg = 4326)\n    else:\n        center = gdf.geometry.centroid.to_crs(epsg = 4326)\n\n    # Calculate center coordinates\n    lat = center.y.mean()\n    lon = center.x.mean()\n\n    # convert to WGS84 for mapping\n    gdf = gdf.to_crs(epsg = 4326)\n\n    # Create base map\n    m = folium.Map(location = [lat, lon], zoom_start = 11)\n\n    # Configure color.\n    # Configure styling based on color_code parameter\n    if color_code:\n        unique_values = gdf[color_code].unique()\n        num_colors = len(unique_values)\n\n        # Use cmocean \"phase\" colormap.\n        cmap = cmo.phase\n\n        # Generate colors for discrete categories.\n        colors = [mcolors.rgb2hex(\n            cmap(i / max(num_colors-1, 1))\n            )\n            for i in range(num_colors)\n            ]\n        color_map = {val: colors[i] for i, val in enumerate(unique_values)}\n\n        # Define style function with color coding.\n        style_function = lambda x: {\n            \"fillColor\": color_map.get(x['properties'][color_code], 'gray'),\n            \"color\": \"gray\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.35\n        }\n\n    else:\n        # Define style function with single color\n        style_function = lambda x: {\n            \"fillColor\": \"blue\",\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.35\n        }\n    \n    # Add GeoJSON layer to map.\n    folium.GeoJson(\n        gdf,\n        name = title,\n        style_function = style_function,\n        tooltip = folium.GeoJsonTooltip(fields = fields) if fields else None\n    ).add_to(m)\n    \n    return m\n\n#______________________________________________________________________________\n\n#______________________________________________________________________________\ndef points_in_neighborhood_map(\n    point_layers,\n    neighborhoods_gdf,\n    council_col = \"council_district\",\n    neighborhood_col = \"neighborhood_name\",\n    point_info_col = None,\n    point_base_color = \"blue\",\n    ranking_col = \"med_underserv_ranking\",\n    start_zoom = 12,\n    point_radius = 4,\n    point_opacity= 0.8,\n    title = None,\n    subtitle = None\n):\n    \"\"\"\n    Create an interactive folium map that displays neighborhood polygons\n    color-coded by council-district, and overlays point layers showing \n    contextual information including council_district, neighborhood, etc.\n    Each point's shade corresponds to the ranking column's value.\n    \n    Args:\n        point_layers: Dictionary of point layers to overlay \n            {'name': GeoDataFrame}\n        neighborhoods_gdf: GeoDataFrame containing Neighborhood polygons \n            and council district column (GeoDataFrame)\n        council_col: name of council district column (string)\n        neighborhood_col: Name of neighborhood column (string)\n        point_info_col: Column in point layer to display in tooltip (string, \n            optional)\n        point_base_color: Base color for points (string)\n        ranking_col: Column to dertermine point shade where lower values \n            are darker, higher values are lighter (string)\n        start_zoom: Initial zoom level (integer)\n        point_radius: Radius of point markers (integer)\n        point_opacity: Opacity of point markers (0-1) (float)\n        title: Map title displayed in top-left corner (string)\n        subtitle: Subtitle displayed below title (string)\n    \n    Returns:\n        folium.Map\n    \"\"\"\n\n    # Normalize crs and ensure all geometries use WGS84 for web mapping\n    neighborhoods = neighborhoods_gdf.to_crs(epsg = 4326)\n    normalized_points = {}\n    all_points = []\n\n    # Reproject each point layer\n    for name, gdf in point_layers.items():\n        gdf = gdf.to_crs(epsg = 4326)\n        normalized_points[name] = gdf\n        all_points.append(gdf)\n\n    # Initialize the map\n    combined_points = gpd.GeoDataFrame(\n        pd.concat(all_points, ignore_index = True), \n        crs = \"EPSG:4326\"\n    )\n    # Calculate centroid of all points\n    center_lat = combined_points.geometry.y.mean()\n    center_lon = combined_points.geometry.x.mean()\n    m = folium.Map(\n        location = [center_lat, center_lon], \n        zoom_start = start_zoom\n    )\n\n    # Add title block to top left if provided\n    if title:\n        title_html = f\"\"\"\n        <div style=\"\n            position: fixed;\n            top: 15px;\n            left: 15px;\n            z-index: 9999;\n            background-color: white;\n            padding: 8px 12px;\n            border-radius: 6px;\n            box-shadow: 0 2px 6px rgba(0,0,0,0.2);\n            font-family: Arial, sans-serif;\n        \">\n            <div style=\"font-size: 14px; font-weight: bold;\">\n                {title}\n            </div>\n            {f'<div style=\"font-size: 12px; color: gray;\">{subtitle}</div>' \n             if subtitle else ''}\n        </div>\n        \"\"\"\n        m.get_root().html.add_child(folium.Element(title_html))\n\n    # Generate distinct colors to color code each council district\n    unique_vals = neighborhoods[council_col].dropna().unique()\n    num_colors = len(unique_vals)\n    cmap = cmo.phase\n    colors = [\n        mcolors.rgb2hex(cmap(i / max(num_colors - 1, 1))) \n        for i in range(num_colors)\n    ]\n    color_map = {val: colors[i] for i, val in enumerate(unique_vals)}\n\n    # Add neighborhood polygons as GeoJSON layer\n    folium.GeoJson(\n        neighborhoods,\n        name=\"Neighborhoods\",\n        style_function = lambda feature: {\n            \"fillColor\": color_map.get(\n                feature[\"properties\"].get(council_col), \"gray\"\n            ),\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.35,\n        },\n        tooltip = folium.GeoJsonTooltip(\n            fields = [council_col, neighborhood_col],\n            aliases = [\"Council District:\", \"Neighborhood:\"],\n        ),\n    ).add_to(m)\n\n    # Set up ranking-based color gradient\n    base_rgb = mcolors.to_rgb(point_base_color)\n\n    # Determine global min/max rankings for consistent shading\n    ranking_exists = any(\n        ranking_col in gdf.columns for gdf in normalized_points.values()\n    )\n    if ranking_exists:\n        all_ranks = pd.concat([\n            gdf[ranking_col] for gdf in normalized_points.values() \n            if ranking_col in gdf.columns\n        ])\n        rank_min = all_ranks.min()\n        rank_max = all_ranks.max()\n\n    # Add each point layer through spatial join with neighborhoods\n    for layer_name, points_gdf in normalized_points.items():\n        # Spacial join to get neighborhood attributes\n        joined = gpd.sjoin(\n            points_gdf,\n            neighborhoods[[neighborhood_col, council_col, \"geometry\"]],\n            how = \"left\",\n            predicate = \"within\"\n        )\n\n        # Add individual point markers\n        for _, row in joined.iterrows():\n            # Create tooltip content\n            tooltip_text = (\n                f\"Neighborhood: {row.get(neighborhood_col, 'N/A')}<br>\"\n                f\"Council District: {row.get(council_col, 'N/A')}<br>\"\n            )\n            if point_info_col:\n                tooltip_text += (\n                    f\"{point_info_col}: {row.get(point_info_col, 'N/A')}\"\n                )\n\n            # Calculate point shade based on ranking column\n            if (ranking_exists and ranking_col in row and \n                    pd.notnull(row.get(ranking_col))):\n                # Normalize ranking to range from 0 to 1\n                rank_range = max(rank_max - rank_min, 1e-6)\n                norm_rank = (row[ranking_col] - rank_min) / rank_range\n                # Lower ranking is darker, higher is lighter\n                color_rgb = tuple([\n                    base_rgb[i] * (1 - 0.5 * norm_rank) \n                    for i in range(3)\n                ])\n                fill_color = mcolors.to_hex(color_rgb)\n            else:\n                fill_color = point_base_color\n\n            folium.CircleMarker(\n                location = [row.geometry.y, row.geometry.x],\n                radius = point_radius,\n                color = fill_color,\n                fill = True,\n                fill_color = fill_color,\n                fill_opacity = point_opacity,\n                tooltip = tooltip_text,\n            ).add_to(m)\n\n    return m\n\n#______________________________________________________________________________\n\n#______________________________________________________________________________\n\ndef assign_points_to_neighborhood(\n    points_gdf, neighborhoods_gdf, neighborhood_cols):\n    \"\"\"\n    Performs a spatial join to determine which neighborhood polygon each point\n    falls into, then attaches neighborhood information to each point.\n\n    Args:\n        points_gdf: Point locations (GeoDataFrame)\n        neighborhoods_gdf: Neighborhood polygons (GeoDataFrame)\n        neighborhood_cols: Columns from neighborhoods_gdf to attach (list[str])\n\n    Returns: \n        GeoDataFrame: a copy of points_gdf with additional columns from \n        neighborhood_cols. Retains all original points (left join).\n    \"\"\"\n\n    # Make a copy to avoid modifying original.\n    points = points_gdf.copy()\n\n    # Automatically set crs to points.crs if they differ.\n    if neighborhoods_gdf.crs != points.crs:\n        neighborhoods_gdf = neighborhoods_gdf.to_crs(points.crs)\n\n    # Left join neighborhoods to points\n    joined = gpd.sjoin(\n        points,\n        neighborhoods_gdf[['geometry'] + neighborhood_cols],\n        how = 'left',\n        predicate = 'within'\n    )\n\n    # drop spatial join helper column\n    joined = joined.drop(columns = 'index_right')\n\n    return joined\n\n#______________________________________________________________________________\n\n#______________________________________________________________________________\ndef density_per_neighborhood(\n    points_gdf, \n    neighborhoods_gdf,\n    neighborhood_col = 'Current_Neighborhoods',\n    neighborhood_name_col = 'neighborhood_name',\n    council_col = 'council_district'):\n    \"\"\"\n    Calculate points per square mile for neighborhoods and attach council \n    district, including raw point counts.\n\n    Returns a DataFrame with columns:\n    [neighborhood_col, points, points_per_sq_mile, council_col]\n    \"\"\"\n\n    # Count points per neighborhood (raw counts)\n    counts = (\n        points_gdf\n        .groupby(neighborhood_col)\n        .size()\n        .rename('points')  # store raw counts\n        .reset_index()\n    )\n\n    # Calculate neighborhood areas in square miles (crs in feet)\n    neighborhoods_gdf = neighborhoods_gdf.to_crs(epsg = 2263) \n    neighborhoods_gdf['area_sq_miles'] = (\n        neighborhoods_gdf.geometry.area / (5280 ** 2)\n    )\n\n    # Merge in council district and area \n    merged = counts.merge(\n        neighborhoods_gdf[\n            [neighborhood_name_col, council_col, 'area_sq_miles']\n        ],\n        left_on = neighborhood_col,\n        right_on = neighborhood_name_col,\n        how = 'left'\n    )\n\n    # Calculate points per square mile and round to nearest tenth\n    merged['points_per_sq_mile'] = (\n        (merged['points'] / merged['area_sq_miles']).round(1)\n        )\n\n    # Keep desired columns\n    merged = merged[\n        [neighborhood_col, 'points', 'points_per_sq_mile', council_col]\n    ]\n\n    # Sort by density descending\n    merged = merged.sort_values(\n        'points_per_sq_mile', \n        ascending = False\n        ).reset_index(drop = True)\n\n    return merged\n\n#______________________________________________________________________________\n\n\n#______________________________________________________________________________\n\ndef flag_underserved_with_green_lights(\n    med_counts, green_counts, threshold = 5):\n    \"\"\"\n    Identify neighborhoods that are medically underserved and\n    have more than or equal to the green light location threshold.\n\n    Args:\n        med_counts: \n            Count of MUAP points in neighborhood (DataFrame)\n        green_counts: \n            Count of Green Light locations in neighborhood (DataFrame)\n        threshold: \n            Minimum number of Green Light Locations for flag\n\n    Returns:\n        merged: DataFrame with medical counts, green light counts, \n            and a flag for neighborhoods that meet threshold\n    \"\"\"\n\n    # Join the DataFrames\n    merged = med_counts.merge(\n        green_counts,\n        on = 'City Neighborhoods', \n        how = 'left', \n        suffixes = ('_med', '_green')\n    )\n\n    # Fill NaN values with 0\n    merged['count_green'] = merged['count_green'].fillna(0)\n\n    # Creates boolean column (True if >= 5)\n    merged['flag_many_green'] = merged['count_green'] >= threshold\n\n    return merged\n\n#______________________________________________________________________________\n\n\n#______________________________________________________________________________\n\ndef neighborhood_choropleth_map(\n    neighborhoods_gdf,\n    value_col = \"request_count\",\n    council_col = \"council_district\",\n    neighborhood_col = \"neighborhood_name\",\n    start_zoom = 12,\n    title = None,\n    subtitle = None):\n    \"\"\"\n    Display a choropleth map of neighborhoods colored by council district,\n    with shading based on request count and hover tooltips.\n    Optional fixed title and subtitle in the top-left corner.\n\n    Args:\n        neighborhoods_gdf: Neighborhood polygons with request counts \n            (GeoDataFrame)\n        value_col: Column with aggregated request counts (string)\n        council_col: Council district column (str)\n        neighborhood_col: Neighborhood name column (str)\n        start_zoom: Initial zoom level (int)\n        title: Optional map title (str)\n        subtitle: Optional map subtitle (str)\n\n    Returns:\n        folium.Map\n    \"\"\"\n\n    # Normalize the coordinate reference system\n    neighborhoods = neighborhoods_gdf.to_crs(epsg = 4326)\n\n    # Fill missing values with 0\n    # This allows us to include neighborhoods with no requests in map\n    neighborhoods[value_col] = neighborhoods[value_col].fillna(0)\n\n    # Calculate the map center\n    center_lat = neighborhoods.geometry.centroid.y.mean()\n    center_lon = neighborhoods.geometry.centroid.x.mean()\n    m = folium.Map(\n        location = [center_lat, center_lon], zoom_start = start_zoom\n    )\n\n    # Add title/subtitle HTML overlay in top-left \n    if title or subtitle:\n        html_content = \"\"\n        if title:\n            html_content += f\"<h4 style='margin:0'>{title}</h4>\"\n        if subtitle:\n            html_content += f\"<p style='margin:0'>{subtitle}</p>\"\n\n        # CSS styling for fixed position overlay with semi-transparent background\n        template = f\"\"\"\n        <div style=\"\n            position: fixed;\n            top: 10px;\n            left: 10px;\n            z-index: 9999;\n            background-color: rgba(255,255,255,0.85);\n            padding: 5px 10px;\n            border-radius: 5px;\n            font-family: sans-serif;\n        \">\n            {html_content}\n        </div>\n        \"\"\"\n        # Add the HTML template to the map\n        macro = MacroElement()\n        macro._template = Template(template)\n        m.get_root().add_child(macro)\n\n    # Create council district base colors\n    # Get all unique council districts\n    unique_vals = neighborhoods[council_col].dropna().unique()\n    # Align number of colors to number of districts\n    num_colors = len(unique_vals)\n    # Use the phase colormap\n    cmap = cmo.phase\n    # Generate evenly-spaced colors from colormap\n    # This ensures distinct coloring\n    colors = [\n        mcolors.rgb2hex(cmap(i / max(num_colors - 1, 1)))\n        for i in range(num_colors)\n    ]\n    # Create a map for council district to color\n    council_color_map = {val: colors[i] for i, val in enumerate(unique_vals)}\n\n    # Normalize request counts for shading\n    # Find the range of request counts\n    vmin = neighborhoods[value_col].min()\n    vmax = neighborhoods[value_col].max()\n\n    def style_function(feature):\n        \"\"\"\n        Define style for each polygon.\n        Combines council distict color with request count shade.\n        \"\"\"\n\n        # Extract properties from the GeoJSON feature\n        props = feature[\"properties\"]\n        council = props.get(council_col)\n        count = props.get(value_col)\n\n        # Get the base color for the council district\n        base_color = council_color_map.get(council, \"#cccccc\")\n\n        # Apply shading based on request count\n        if count is not None and vmax > vmin:\n            # Normalize the count to 0 to 1\n            norm = (count - vmin) / (vmax - vmin)\n            # Convert hex to RGB to manipulate\n            base_rgb = mcolors.to_rgb(base_color)\n            # Darken color based on request count\n            shade_rgb = tuple(c * (0.4 + 0.6 * (1 - norm)) for c in base_rgb)\n            # Convert back to hex\n            fill_color = mcolors.to_hex(shade_rgb)\n        else:\n            # Use base color if there is no count\n            fill_color = base_color\n\n        # Return the style dictionary for the polygon\n        return {\n            \"fillColor\": fill_color,\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.6,\n        }\n\n    # GeoJson with hover\n    # Add neighborhood polygons to the map\n    folium.GeoJson(\n        neighborhoods,\n        name = \"Neighborhood Requests\",\n        style_function = style_function,\n        # Configure the tooltip\n        tooltip = folium.GeoJsonTooltip(\n            fields = [council_col, neighborhood_col, value_col],\n            aliases = [\n                \"Council District:\",\n                \"Neighborhood:\",\n                \"Request Count:\",\n            ],\n            localize = True,\n            sticky = True,\n        ),\n    ).add_to(m)\n\n    return m\n#______________________________________________________________________________\n\n\n#______________________________________________________________________________\n\n# Calculate the average points_per_square_mile \n# and the min/max points_per_square_mile per council district\n\ndef council_district_stats(\n    neighborhood_density_df, \n    council_col = None, \n    neighborhood_col = None,  \n    density_col = 'points_per_sq_mile',\n    points_col = 'points'):\n    \"\"\"\n    Calculate higher-level district statistics of points per square mile\n    (council districts, neighborhood clusters, etc.).\n\n    Args:\n        neighborhood_density_df: Neighborhood-level density with columns for \n            neighborhood, density, and higher-level grouping. (pd.DataFrame)\n        council_col: Column name for higher-level grouping \n            (e.g., council_district, neighborhood_cluster) (string)\n        neighborhood_col: Column name for neighborhood in the DataFrame \n            (string)\n        density_col: Column name for points per square mile (string)\n        points_col: Column name for total points in the neighborhood (string)\n\n    Returns:\n        District-level stats: average, min, max density and neighborhoods \n        corresponding to min/max (pd.DataFrame)\n    \"\"\"\n\n#______________________________________________________________________________\n\n    # Validate input columns exist\n    for col in [council_col, neighborhood_col, density_col, points_col]:\n        if col not in neighborhood_density_df.columns:\n            available = neighborhood_density_df.columns.tolist()\n            raise ValueError(\n                f\"Column '{col}' not found in DataFrame. \"\n                f\"Available columns: {available}\"\n            )\n    # Group by the higher-level district and calculate mean/min/max densities\n    council_stats = (\n        neighborhood_density_df\n        .groupby(council_col)[density_col]\n        .agg(\n            avg_points_per_sq_mile='mean',\n            min_points_per_sq_mile='min',\n            max_points_per_sq_mile='max'\n        )\n        .round(1)\n        .reset_index()\n    )\n\n    # Total points per district\n    total_points = (\n        neighborhood_density_df\n        .groupby(council_col)[points_col]\n        .sum()\n        .reset_index(name = 'total_points')\n    )\n\n    council_stats = council_stats.merge(total_points, on = council_col)\n\n    # Find neighborhoods corresponding to min and max densities\n    min_neighborhoods = (\n        neighborhood_density_df\n        .groupby(council_col)\n        .apply(\n            lambda df: ', '.join(\n                df.loc[\n                    df[density_col] == df[density_col].min(),\n                    neighborhood_col\n                ]\n            )\n        )\n        .reset_index(name = 'min_neighborhood')\n    )\n\n    max_neighborhoods = (\n        neighborhood_density_df\n        .groupby(council_col)\n        .apply(\n            lambda df: ', '.join(\n                df.loc[\n                    df[density_col] == df[density_col].max(),\n                    neighborhood_col\n                ]\n            )\n        )\n        .reset_index(name = 'max_neighborhood')\n    )\n\n    council_stats = council_stats.merge(\n        min_neighborhoods, \n        on = council_col\n    )\n    council_stats = council_stats.merge(\n        max_neighborhoods, \n        on = council_col\n    )\n\n    # Sort by average density descending\n    council_stats = council_stats.sort_values(\n        'avg_points_per_sq_mile',\n        ascending = False\n    ).reset_index(drop = True)\n\n    return council_stats\n#______________________________________________________________________________\n\n#______________________________________________________________________________\n\ndef calculate_district_imu(\n    current_neighborhoods_gdf,\n    medically_underserved_gdf,\n    district_col = \"council_district\",\n    neighborhood_col = \"neighborhood_name\",\n    imu_col = \"med_underserv_ranking\",\n    non_residential_names = None,\n    fallback_value = 70):\n    \"\"\"\n    Calculate area-weighted Index of Medical Underservice (IMU) for each\n    district and identify the most underserved neighborhood per district.\n\n    Args:\n        current_neighborhoods_gdf: GeoDataFrame of neighborhood polygons\n        medically_underserved_gdf: GeoDataFrame of IMU areas/rankings\n        district_col: Column name for district identifier (string)\n        neighborhood_col: Column name for neighborhood name (string)\n        imu_col: Column name for medical underservice ranking (string)\n        non_residential_names: Set of neighborhood names to exclude (set)\n        fallback_value: IMU value for areas with no data (int/float)\n\n    Returns:\n        DataFrame with district-level IMU statistics\n    \"\"\"\n\n    # Filter out non-residential neighborhoods\n    if non_residential_names is not None:\n        current_neighborhoods_gdf = current_neighborhoods_gdf[\n            ~current_neighborhoods_gdf[neighborhood_col].isin(\n                non_residential_names\n            )\n        ].copy()\n\n    # Project to equal-area crs\n    neighborhoods_proj = current_neighborhoods_gdf.to_crs(epsg = 3857)\n    imu_proj = medically_underserved_gdf.to_crs(epsg = 3857)\n\n    # Spatial join to match neighborhoods with MUAPs\n    joined = gpd.sjoin(\n        neighborhoods_proj,\n        imu_proj,\n        how = \"left\",\n        predicate  =\"intersects\"\n    )\n\n    # Aggregate IMU at neighborhood level \n    # Take minimum if there's multiple overlaps\n    neighborhood_imu = (\n        joined.groupby([neighborhood_col, district_col, \"geometry\"])\n        [imu_col]\n        .min()\n        .reset_index()\n    )\n\n    # Make it a GeoDataFrame so we can compute area\n    neighborhood_imu = gpd.GeoDataFrame(\n        neighborhood_imu, \n        geometry = \"geometry\", \n        crs = current_neighborhoods_gdf.crs\n    )\n\n    # Assign fallback IMU t neighborhoods missing data\n    neighborhood_imu[imu_col] = neighborhood_imu[imu_col].fillna(\n        fallback_value\n    )\n\n    # Compute area in square miles (1 sq mi = 2,589,988.11 sq meters)\n    neighborhood_imu[\"area_sq_mi\"] = (\n        neighborhood_imu.geometry.area / 2_589_988.11\n    )\n\n    # Calculate weighted IMU (IMU score Ã— area)\n    neighborhood_imu[\"weighted_imu\"] = (\n        neighborhood_imu[imu_col] * neighborhood_imu[\"area_sq_mi\"]\n    )\n\n    # Aggregate by district\n    district_agg = (\n        neighborhood_imu\n        .groupby(district_col)\n        .agg(\n            total_weighted_imu = (\"weighted_imu\", \"sum\"),\n            total_area = (\"area_sq_mi\", \"sum\")\n        )\n        .reset_index()\n    )\n\n    # Calculate area-weighted average IMU per district\n    district_agg[\"area_weighted_IMU\"] = (\n        district_agg[\"total_weighted_imu\"] / district_agg[\"total_area\"]\n    ).round(0).astype(int)\n\n    # Find the most underserved neighborhood in each district (lowest IMU)\n    min_neighborhood = (\n        neighborhood_imu.groupby(district_col)\n        .apply(\n            lambda x: x.loc[\n                x[imu_col].idxmin(),\n                [neighborhood_col, imu_col]\n            ]\n        )\n        .reset_index()\n        .rename(columns = {\n            neighborhood_col: \"lowest_ranked_neighborhood\",\n            imu_col: \"lowest_neighborhood_IMU\"\n        })\n    )\n\n    # Merge district-level stats with most underserved neighborhoods\n    district_results = district_agg.merge(\n        min_neighborhood,\n        on = district_col\n    )\n\n    # Sort by area-weighted IMU (ascending = most underserved first)\n    district_results = district_results.sort_values(\n        \"area_weighted_IMU\"\n    ).reset_index(drop = True)\n\n    return district_results[\n        [\n            district_col,\n            \"area_weighted_IMU\",\n            \"lowest_ranked_neighborhood\",\n            \"lowest_neighborhood_IMU\"\n        ]\n    ]\n\n#______________________________________________________________________________\n"},"outputs":[],"source":"# Load json to parse JSON text for functions module\nimport json\n\n# Load sys so Python can locate files in list of directories\nimport sys\n\n# Load os to get the current directory path\nimport os\n\n# load inspect to examine Python objects\nimport inspect\n\n# Load geopandas library to work with geoJSON files.\nimport geopandas as gpd\n\n# Load pandas library for data manipulation and analysis.\nimport pandas as pd\n\n# Load matplotlib library for data visualization.\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\n\n# Load folium to visualize geospatial data.\nimport folium\n\n# Load cmocean for colormaps.\nimport cmocean.cm as cmo\n\n# Load datetime to manipulate dates and times.\nfrom datetime import datetime\n\n# Load requests to conduct HTTP requests to an API.\nimport requests\n\n# Load time so we can time and optimize queries.\nimport time\n\n# Load Point to use in coordinate mapping.\nfrom shapely.geometry import Point\n\n\n# for cloropleth map function\nfrom branca.element import MacroElement\n\n# for cloropleth map function\nfrom jinja2 import Template\n\n#______________________________________________________________________________\n\ndef summarize_dataframe(df):\n    \"\"\"\n    Summarizes a DataFrame/GeoDataFrame with column-level statistics.\n    Args:\n        df: a pandas DataFrame or geopandas GeoDataFrame to summarize\n    Returns:\n        DataFrame with summary statistics for each column:\n            Type: column data type\n            Missing: count of missing values\n            Missing %: percent of missing values\n            Unique: count of unique values\n            min, max, mean: minimum, maximum, and mean (numeric columns only)\n    Raises:\n        AttributeError: If df input is not a DataFrame-like object\n        ZeroDivisionError: If DataFrame is empty\n    \"\"\"\n    summary = {\n        col: {\n            'Type': df[col].dtype,\n            'Missing': df[col].isnull().sum(),\n            'Missing %': round(df[col].isnull().sum() / len(df) * 100, 2),\n            'Unique': df[col].nunique()\n        }\n        for col in df.columns\n    }\n    \n    # Transpose summary so each row represents one column from df.\n    summary_df = pd.DataFrame(summary).T\n\n    # Grab numeric columns only (geometry is excluded automatically).\n    numeric_cols = df.select_dtypes(include='number')\n\n    # Compute summary statistics for numeric columns.\n    if not numeric_cols.empty:\n        summary_stats = numeric_cols.agg(['min', 'max', 'mean']).T.round(2)\n        summary_df = summary_df.join(summary_stats)\n\n    return summary_df\n\n#______________________________________________________________________________\n\n#______________________________________________________________________________\n\ndef group_and_sum(df, column):\n    \"\"\"\n    Groups a DataFrame/GeoDataFrame by a specified column,\n    and sums the numeric columns.\n    Args:\n        df: a pandas DataFrame or geopandas GeoDataFrame\n        column: Column name to group by (string)\n    Returns:\n        pandas DataFrame with grouped data and summed numeric values\n    Raises:\n        ValueError: If df contains no numeric columns to sum\n    \"\"\"\n\n    # Check for numeric columns before grouping.\n    numeric_cols = df.select_dtypes(include='number').columns\n    numeric_cols = [col for col in numeric_cols if col != column]\n\n    if len(numeric_cols) == 0:\n        raise ValueError(\"DataFrame contains no numeric columns to sum\")\n\n    return df.groupby(column).sum()\n\n#______________________________________________________________________________\n\n#______________________________________________________________________________\n\ndef min_max(df, column):\n    \"\"\"\n    Computes the minimum and maximum values of a column.\n    Args:\n        df: a pandas DataFrame\n        column: Column name to compute min/max for (string)\n    Returns:\n        (min_value, max_value) for the specified column (tuple)\n    Raises:\n        KeyError: If the column does not exist in the DataFrame.\n    \"\"\"\n    return df[column].min(), df[column].max()\n    \n#______________________________________________________________________________\n\n#______________________________________________________________________________\n\ndef df_to_geodataframe(df, lon_col, lat_col, crs = \"EPSG:4326\"):\n    \"\"\"\n    Convert a pandas DataFrame with lon/lat columns into a GeoDataFrame.\n    Ensures longitude and latitude columns to numeric values, drops\n    rows with missing coordinates, and creates Point geometry objects.\n    Args:\n        df: pandas DataFrame\n        lon_col: Longitude column name (string)\n        lat_col: Latitude column name (string)\n        crs: Coordinate reference system (string, default: \"EPSG:4326\")\n    Returns:\n        geopandas.GeoDataFrame with Points in specified CRS\n    \"\"\"\n\n    df = df.copy()\n\n    # Ensure latitude and longitude columns are numeric.\n    df[lat_col] = pd.to_numeric(df[lat_col], errors = \"coerce\")\n    df[lon_col] = pd.to_numeric(df[lon_col], errors = \"coerce\")\n\n    # Drop rows with missing data.\n    df = df.dropna(subset = [lon_col, lat_col])\n\n    # Create geometry object using Shapely Point.\n    df[\"geometry\"] = [Point(xy) for xy in zip(df[lon_col], df[lat_col])]\n\n    # Convert DataFrame to a GeoDataFrame.\n    gdf = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=crs)\n\n    return gdf\n\n#______________________________________________________________________________\n\n#______________________________________________________________________________\n\ndef create_map_orig(gdf, fields = None, title = None, color_code = None):\n    \"\"\"\n    Create an interactive folium map.\n    Centers the map of the gdf's center and handles coordinate \n    transformations. Optionally color-codes features by a specified column.\n    Args:\n        gdf: GeoDataFrame to visualize\n        fields: field names to display in the tooltip (list, default = None)\n        title: Name of map (string, default = None)\n        color_code: Column name for color coding features (string, \n        default = None)\n    Returns:\n        folium.Map object with the GeoDataFrame layer added\n    \"\"\"\n\n    # Make a copy to avoid modifying the original GeoDataFrame.\n    gdf = gdf.copy()\n    \n    # Convert datetime columns to strings for JSON serialization.\n    datetime_cols = gdf.select_dtypes(\n        include = ['datetime64', 'datetime']\n        ).columns\n    for col in datetime_cols:\n        gdf[col] = gdf[col].astype(str)\n\n    # Calculate center based on CRS.\n    # If already in geographic crs, then\n    # project crs temporarily for centroid calculation.\n    if gdf.crs and gdf.crs.is_geographic:\n        # Use the UTM zone 17N for Detroit area.\n        gdf_projected = gdf.to_crs(epsg = 32617)\n        # Calculate center and project back to geographic.\n        center = gdf_projected.geometry.centroid.to_crs(epsg = 4326)\n    else:\n        center = gdf.geometry.centroid.to_crs(epsg = 4326)\n\n    # Calculate center\n    lat = center.y.mean()\n    lon = center.x.mean()\n\n    # Convert the crs to latitude/longitude for folium mapping.\n    gdf = gdf.to_crs(epsg = 4326)\n\n    # Create a centered base map with zoom level of 11.\n    map = folium.Map(\n        location = [lat, lon],\n        zoom_start = 11\n        )\n\n    # Configure styling based on color_code parameter.\n    if color_code:\n        # Get unique values and generate colors dynamically.\n        unique_values = gdf[color_code].unique()\n        num_colors = len(unique_values)\n        # Choose colormap based on number of categories.\n        if num_colors <= 10:\n            cmap = plt.cm.get_cmap('tab10')\n        elif num_colors <= 20:\n            cmap = plt.cm.get_cmap('tab20')\n        else:\n            cmap = plt.cm.get_cmap('hsv')\n        # Generate colors.\n        colors = [mcolors.rgb2hex(\n            cmap(i / num_colors)\n            ) \n            for i in range(num_colors)\n            ]\n        # Create color map dictionary.\n        color_map = {val: colors[i] for i, val in enumerate(unique_values)}\n        # Define style function with color coding.\n        style_function = lambda x: {\n            \"fillColor\": color_map.get(x['properties'][color_code], 'gray'),\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.7\n        }\n\n    # If color code is not specified, use one color.  \n    else:\n        # Define style function with single color.\n        style_function = lambda x: {\n            \"fillColor\": \"blue\",\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.5\n        }\n    \n    # Add GeoJSON layer to map.\n    folium.GeoJson(\n        gdf,\n        name = title,\n        style_function = style_function,\n        tooltip = folium.GeoJsonTooltip(\n            fields = fields\n            ) \n            if fields \n            else None\n    ).add_to(map)\n    \n    return map\n\n#______________________________________________________________________________\n\n#______________________________________________________________________________\n\ndef create_map(gdf, fields = None, title = None, color_code = None):\n    \"\"\"\n    Create an interactive folium map from a GeoDataFrame.\n    Centers the map on the GeoDataFrame's centroid and uses a muted \n    cmocean color scheme for better visibility.\n    Args:\n        gdf: geopandas.GeoDataFrame to visualize\n        fields: Field names to display in tooltip (list, default = None)\n        title: Name of the map layer (string, default = None)\n        color_code: column name for color coding features \n        (string, default = None)\n    Returns:\n        folium.Map object with the GeoDataFrame layer added\n    \"\"\"\n\n    gdf = gdf.copy()\n    \n    # Convert datetime columns to strings for JSON serialization\n    datetime_cols = gdf.select_dtypes(\n        include = ['datetime64', 'datetime']\n        ).columns\n    for col in datetime_cols:\n        gdf[col] = gdf[col].astype(str)\n\n    # Calculate center based on CRS\n    # If already in geographic CRS, project temporarily for accurate centroid\n    if gdf.crs and gdf.crs.is_geographic:\n        # Use UTM zone 17N for Detroit area\n        gdf_projected = gdf.to_crs(epsg = 32617)\n        # Project back to EPSG:4326 immediately\n        center = gdf_projected.geometry.centroid.to_crs(epsg = 4326)\n    else:\n        center = gdf.geometry.centroid.to_crs(epsg = 4326)\n\n    # Calculate center coordinates\n    lat = center.y.mean()\n    lon = center.x.mean()\n\n    # convert to WGS84 for mapping\n    gdf = gdf.to_crs(epsg = 4326)\n\n    # Create base map\n    m = folium.Map(location = [lat, lon], zoom_start = 11)\n\n    # Configure color.\n    # Configure styling based on color_code parameter\n    if color_code:\n        unique_values = gdf[color_code].unique()\n        num_colors = len(unique_values)\n\n        # Use cmocean \"phase\" colormap.\n        cmap = cmo.phase\n\n        # Generate colors for discrete categories.\n        colors = [mcolors.rgb2hex(\n            cmap(i / max(num_colors-1, 1))\n            )\n            for i in range(num_colors)\n            ]\n        color_map = {val: colors[i] for i, val in enumerate(unique_values)}\n\n        # Define style function with color coding.\n        style_function = lambda x: {\n            \"fillColor\": color_map.get(x['properties'][color_code], 'gray'),\n            \"color\": \"gray\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.35\n        }\n\n    else:\n        # Define style function with single color\n        style_function = lambda x: {\n            \"fillColor\": \"blue\",\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.35\n        }\n    \n    # Add GeoJSON layer to map.\n    folium.GeoJson(\n        gdf,\n        name = title,\n        style_function = style_function,\n        tooltip = folium.GeoJsonTooltip(fields = fields) if fields else None\n    ).add_to(m)\n    \n    return m\n\n#______________________________________________________________________________\n\n#______________________________________________________________________________\ndef points_in_neighborhood_map(\n    point_layers,\n    neighborhoods_gdf,\n    council_col = \"council_district\",\n    neighborhood_col = \"neighborhood_name\",\n    point_info_col = None,\n    point_base_color = \"blue\",\n    ranking_col = \"med_underserv_ranking\",\n    start_zoom = 12,\n    point_radius = 4,\n    point_opacity= 0.8,\n    title = None,\n    subtitle = None\n):\n    \"\"\"\n    Create an interactive folium map that displays neighborhood polygons\n    color-coded by council-district, and overlays point layers showing \n    contextual information including council_district, neighborhood, etc.\n    Each point's shade corresponds to the ranking column's value.\n    \n    Args:\n        point_layers: Dictionary of point layers to overlay \n            {'name': GeoDataFrame}\n        neighborhoods_gdf: GeoDataFrame containing Neighborhood polygons \n            and council district column (GeoDataFrame)\n        council_col: name of council district column (string)\n        neighborhood_col: Name of neighborhood column (string)\n        point_info_col: Column in point layer to display in tooltip (string, \n            optional)\n        point_base_color: Base color for points (string)\n        ranking_col: Column to dertermine point shade where lower values \n            are darker, higher values are lighter (string)\n        start_zoom: Initial zoom level (integer)\n        point_radius: Radius of point markers (integer)\n        point_opacity: Opacity of point markers (0-1) (float)\n        title: Map title displayed in top-left corner (string)\n        subtitle: Subtitle displayed below title (string)\n    \n    Returns:\n        folium.Map\n    \"\"\"\n\n    # Normalize crs and ensure all geometries use WGS84 for web mapping\n    neighborhoods = neighborhoods_gdf.to_crs(epsg = 4326)\n    normalized_points = {}\n    all_points = []\n\n    # Reproject each point layer\n    for name, gdf in point_layers.items():\n        gdf = gdf.to_crs(epsg = 4326)\n        normalized_points[name] = gdf\n        all_points.append(gdf)\n\n    # Initialize the map\n    combined_points = gpd.GeoDataFrame(\n        pd.concat(all_points, ignore_index = True), \n        crs = \"EPSG:4326\"\n    )\n    # Calculate centroid of all points\n    center_lat = combined_points.geometry.y.mean()\n    center_lon = combined_points.geometry.x.mean()\n    m = folium.Map(\n        location = [center_lat, center_lon], \n        zoom_start = start_zoom\n    )\n\n    # Add title block to top left if provided\n    if title:\n        title_html = f\"\"\"\n        <div style=\"\n            position: fixed;\n            top: 15px;\n            left: 15px;\n            z-index: 9999;\n            background-color: white;\n            padding: 8px 12px;\n            border-radius: 6px;\n            box-shadow: 0 2px 6px rgba(0,0,0,0.2);\n            font-family: Arial, sans-serif;\n        \">\n            <div style=\"font-size: 14px; font-weight: bold;\">\n                {title}\n            </div>\n            {f'<div style=\"font-size: 12px; color: gray;\">{subtitle}</div>' \n             if subtitle else ''}\n        </div>\n        \"\"\"\n        m.get_root().html.add_child(folium.Element(title_html))\n\n    # Generate distinct colors to color code each council district\n    unique_vals = neighborhoods[council_col].dropna().unique()\n    num_colors = len(unique_vals)\n    cmap = cmo.phase\n    colors = [\n        mcolors.rgb2hex(cmap(i / max(num_colors - 1, 1))) \n        for i in range(num_colors)\n    ]\n    color_map = {val: colors[i] for i, val in enumerate(unique_vals)}\n\n    # Add neighborhood polygons as GeoJSON layer\n    folium.GeoJson(\n        neighborhoods,\n        name=\"Neighborhoods\",\n        style_function = lambda feature: {\n            \"fillColor\": color_map.get(\n                feature[\"properties\"].get(council_col), \"gray\"\n            ),\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.35,\n        },\n        tooltip = folium.GeoJsonTooltip(\n            fields = [council_col, neighborhood_col],\n            aliases = [\"Council District:\", \"Neighborhood:\"],\n        ),\n    ).add_to(m)\n\n    # Set up ranking-based color gradient\n    base_rgb = mcolors.to_rgb(point_base_color)\n\n    # Determine global min/max rankings for consistent shading\n    ranking_exists = any(\n        ranking_col in gdf.columns for gdf in normalized_points.values()\n    )\n    if ranking_exists:\n        all_ranks = pd.concat([\n            gdf[ranking_col] for gdf in normalized_points.values() \n            if ranking_col in gdf.columns\n        ])\n        rank_min = all_ranks.min()\n        rank_max = all_ranks.max()\n\n    # Add each point layer through spatial join with neighborhoods\n    for layer_name, points_gdf in normalized_points.items():\n        # Spacial join to get neighborhood attributes\n        joined = gpd.sjoin(\n            points_gdf,\n            neighborhoods[[neighborhood_col, council_col, \"geometry\"]],\n            how = \"left\",\n            predicate = \"within\"\n        )\n\n        # Add individual point markers\n        for _, row in joined.iterrows():\n            # Create tooltip content\n            tooltip_text = (\n                f\"Neighborhood: {row.get(neighborhood_col, 'N/A')}<br>\"\n                f\"Council District: {row.get(council_col, 'N/A')}<br>\"\n            )\n            if point_info_col:\n                tooltip_text += (\n                    f\"{point_info_col}: {row.get(point_info_col, 'N/A')}\"\n                )\n\n            # Calculate point shade based on ranking column\n            if (ranking_exists and ranking_col in row and \n                    pd.notnull(row.get(ranking_col))):\n                # Normalize ranking to range from 0 to 1\n                rank_range = max(rank_max - rank_min, 1e-6)\n                norm_rank = (row[ranking_col] - rank_min) / rank_range\n                # Lower ranking is darker, higher is lighter\n                color_rgb = tuple([\n                    base_rgb[i] * (1 - 0.5 * norm_rank) \n                    for i in range(3)\n                ])\n                fill_color = mcolors.to_hex(color_rgb)\n            else:\n                fill_color = point_base_color\n\n            folium.CircleMarker(\n                location = [row.geometry.y, row.geometry.x],\n                radius = point_radius,\n                color = fill_color,\n                fill = True,\n                fill_color = fill_color,\n                fill_opacity = point_opacity,\n                tooltip = tooltip_text,\n            ).add_to(m)\n\n    return m\n\n#______________________________________________________________________________\n\n#______________________________________________________________________________\n\ndef assign_points_to_neighborhood(\n    points_gdf, neighborhoods_gdf, neighborhood_cols):\n    \"\"\"\n    Performs a spatial join to determine which neighborhood polygon each point\n    falls into, then attaches neighborhood information to each point.\n\n    Args:\n        points_gdf: Point locations (GeoDataFrame)\n        neighborhoods_gdf: Neighborhood polygons (GeoDataFrame)\n        neighborhood_cols: Columns from neighborhoods_gdf to attach (list[str])\n\n    Returns: \n        GeoDataFrame: a copy of points_gdf with additional columns from \n        neighborhood_cols. Retains all original points (left join).\n    \"\"\"\n\n    # Make a copy to avoid modifying original.\n    points = points_gdf.copy()\n\n    # Automatically set crs to points.crs if they differ.\n    if neighborhoods_gdf.crs != points.crs:\n        neighborhoods_gdf = neighborhoods_gdf.to_crs(points.crs)\n\n    # Left join neighborhoods to points\n    joined = gpd.sjoin(\n        points,\n        neighborhoods_gdf[['geometry'] + neighborhood_cols],\n        how = 'left',\n        predicate = 'within'\n    )\n\n    # drop spatial join helper column\n    joined = joined.drop(columns = 'index_right')\n\n    return joined\n\n#______________________________________________________________________________\n\n#______________________________________________________________________________\ndef density_per_neighborhood(\n    points_gdf, \n    neighborhoods_gdf,\n    neighborhood_col = 'Current_Neighborhoods',\n    neighborhood_name_col = 'neighborhood_name',\n    council_col = 'council_district'):\n    \"\"\"\n    Calculate points per square mile for neighborhoods and attach council \n    district, including raw point counts.\n\n    Returns a DataFrame with columns:\n    [neighborhood_col, points, points_per_sq_mile, council_col]\n    \"\"\"\n\n    # Count points per neighborhood (raw counts)\n    counts = (\n        points_gdf\n        .groupby(neighborhood_col)\n        .size()\n        .rename('points')  # store raw counts\n        .reset_index()\n    )\n\n    # Calculate neighborhood areas in square miles (crs in feet)\n    neighborhoods_gdf = neighborhoods_gdf.to_crs(epsg = 2263) \n    neighborhoods_gdf['area_sq_miles'] = (\n        neighborhoods_gdf.geometry.area / (5280 ** 2)\n    )\n\n    # Merge in council district and area \n    merged = counts.merge(\n        neighborhoods_gdf[\n            [neighborhood_name_col, council_col, 'area_sq_miles']\n        ],\n        left_on = neighborhood_col,\n        right_on = neighborhood_name_col,\n        how = 'left'\n    )\n\n    # Calculate points per square mile and round to nearest tenth\n    merged['points_per_sq_mile'] = (\n        (merged['points'] / merged['area_sq_miles']).round(1)\n        )\n\n    # Keep desired columns\n    merged = merged[\n        [neighborhood_col, 'points', 'points_per_sq_mile', council_col]\n    ]\n\n    # Sort by density descending\n    merged = merged.sort_values(\n        'points_per_sq_mile', \n        ascending = False\n        ).reset_index(drop = True)\n\n    return merged\n\n#______________________________________________________________________________\n\n\n#______________________________________________________________________________\n\ndef flag_underserved_with_green_lights(\n    med_counts, green_counts, threshold = 5):\n    \"\"\"\n    Identify neighborhoods that are medically underserved and\n    have more than or equal to the green light location threshold.\n\n    Args:\n        med_counts: \n            Count of MUAP points in neighborhood (DataFrame)\n        green_counts: \n            Count of Green Light locations in neighborhood (DataFrame)\n        threshold: \n            Minimum number of Green Light Locations for flag\n\n    Returns:\n        merged: DataFrame with medical counts, green light counts, \n            and a flag for neighborhoods that meet threshold\n    \"\"\"\n\n    # Join the DataFrames\n    merged = med_counts.merge(\n        green_counts,\n        on = 'City Neighborhoods', \n        how = 'left', \n        suffixes = ('_med', '_green')\n    )\n\n    # Fill NaN values with 0\n    merged['count_green'] = merged['count_green'].fillna(0)\n\n    # Creates boolean column (True if >= 5)\n    merged['flag_many_green'] = merged['count_green'] >= threshold\n\n    return merged\n\n#______________________________________________________________________________\n\n\n#______________________________________________________________________________\n\ndef neighborhood_choropleth_map(\n    neighborhoods_gdf,\n    value_col = \"request_count\",\n    council_col = \"council_district\",\n    neighborhood_col = \"neighborhood_name\",\n    start_zoom = 12,\n    title = None,\n    subtitle = None):\n    \"\"\"\n    Display a choropleth map of neighborhoods colored by council district,\n    with shading based on request count and hover tooltips.\n    Optional fixed title and subtitle in the top-left corner.\n\n    Args:\n        neighborhoods_gdf: Neighborhood polygons with request counts \n            (GeoDataFrame)\n        value_col: Column with aggregated request counts (string)\n        council_col: Council district column (str)\n        neighborhood_col: Neighborhood name column (str)\n        start_zoom: Initial zoom level (int)\n        title: Optional map title (str)\n        subtitle: Optional map subtitle (str)\n\n    Returns:\n        folium.Map\n    \"\"\"\n\n    # Normalize the coordinate reference system\n    neighborhoods = neighborhoods_gdf.to_crs(epsg = 4326)\n\n    # Fill missing values with 0\n    # This allows us to include neighborhoods with no requests in map\n    neighborhoods[value_col] = neighborhoods[value_col].fillna(0)\n\n    # Calculate the map center\n    center_lat = neighborhoods.geometry.centroid.y.mean()\n    center_lon = neighborhoods.geometry.centroid.x.mean()\n    m = folium.Map(\n        location = [center_lat, center_lon], zoom_start = start_zoom\n    )\n\n    # Add title/subtitle HTML overlay in top-left \n    if title or subtitle:\n        html_content = \"\"\n        if title:\n            html_content += f\"<h4 style='margin:0'>{title}</h4>\"\n        if subtitle:\n            html_content += f\"<p style='margin:0'>{subtitle}</p>\"\n\n        # CSS styling for fixed position overlay with semi-transparent background\n        template = f\"\"\"\n        <div style=\"\n            position: fixed;\n            top: 10px;\n            left: 10px;\n            z-index: 9999;\n            background-color: rgba(255,255,255,0.85);\n            padding: 5px 10px;\n            border-radius: 5px;\n            font-family: sans-serif;\n        \">\n            {html_content}\n        </div>\n        \"\"\"\n        # Add the HTML template to the map\n        macro = MacroElement()\n        macro._template = Template(template)\n        m.get_root().add_child(macro)\n\n    # Create council district base colors\n    # Get all unique council districts\n    unique_vals = neighborhoods[council_col].dropna().unique()\n    # Align number of colors to number of districts\n    num_colors = len(unique_vals)\n    # Use the phase colormap\n    cmap = cmo.phase\n    # Generate evenly-spaced colors from colormap\n    # This ensures distinct coloring\n    colors = [\n        mcolors.rgb2hex(cmap(i / max(num_colors - 1, 1)))\n        for i in range(num_colors)\n    ]\n    # Create a map for council district to color\n    council_color_map = {val: colors[i] for i, val in enumerate(unique_vals)}\n\n    # Normalize request counts for shading\n    # Find the range of request counts\n    vmin = neighborhoods[value_col].min()\n    vmax = neighborhoods[value_col].max()\n\n    def style_function(feature):\n        \"\"\"\n        Define style for each polygon.\n        Combines council distict color with request count shade.\n        \"\"\"\n\n        # Extract properties from the GeoJSON feature\n        props = feature[\"properties\"]\n        council = props.get(council_col)\n        count = props.get(value_col)\n\n        # Get the base color for the council district\n        base_color = council_color_map.get(council, \"#cccccc\")\n\n        # Apply shading based on request count\n        if count is not None and vmax > vmin:\n            # Normalize the count to 0 to 1\n            norm = (count - vmin) / (vmax - vmin)\n            # Convert hex to RGB to manipulate\n            base_rgb = mcolors.to_rgb(base_color)\n            # Darken color based on request count\n            shade_rgb = tuple(c * (0.4 + 0.6 * (1 - norm)) for c in base_rgb)\n            # Convert back to hex\n            fill_color = mcolors.to_hex(shade_rgb)\n        else:\n            # Use base color if there is no count\n            fill_color = base_color\n\n        # Return the style dictionary for the polygon\n        return {\n            \"fillColor\": fill_color,\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.6,\n        }\n\n    # GeoJson with hover\n    # Add neighborhood polygons to the map\n    folium.GeoJson(\n        neighborhoods,\n        name = \"Neighborhood Requests\",\n        style_function = style_function,\n        # Configure the tooltip\n        tooltip = folium.GeoJsonTooltip(\n            fields = [council_col, neighborhood_col, value_col],\n            aliases = [\n                \"Council District:\",\n                \"Neighborhood:\",\n                \"Request Count:\",\n            ],\n            localize = True,\n            sticky = True,\n        ),\n    ).add_to(m)\n\n    return m\n#______________________________________________________________________________\n\n\n#______________________________________________________________________________\n\n# Calculate the average points_per_square_mile \n# and the min/max points_per_square_mile per council district\n\ndef council_district_stats(\n    neighborhood_density_df, \n    council_col = None, \n    neighborhood_col = None,  \n    density_col = 'points_per_sq_mile',\n    points_col = 'points'):\n    \"\"\"\n    Calculate higher-level district statistics of points per square mile\n    (council districts, neighborhood clusters, etc.).\n\n    Args:\n        neighborhood_density_df: Neighborhood-level density with columns for \n            neighborhood, density, and higher-level grouping. (pd.DataFrame)\n        council_col: Column name for higher-level grouping \n            (e.g., council_district, neighborhood_cluster) (string)\n        neighborhood_col: Column name for neighborhood in the DataFrame \n            (string)\n        density_col: Column name for points per square mile (string)\n        points_col: Column name for total points in the neighborhood (string)\n\n    Returns:\n        District-level stats: average, min, max density and neighborhoods \n        corresponding to min/max (pd.DataFrame)\n    \"\"\"\n\n#______________________________________________________________________________\n\n    # Validate input columns exist\n    for col in [council_col, neighborhood_col, density_col, points_col]:\n        if col not in neighborhood_density_df.columns:\n            available = neighborhood_density_df.columns.tolist()\n            raise ValueError(\n                f\"Column '{col}' not found in DataFrame. \"\n                f\"Available columns: {available}\"\n            )\n    # Group by the higher-level district and calculate mean/min/max densities\n    council_stats = (\n        neighborhood_density_df\n        .groupby(council_col)[density_col]\n        .agg(\n            avg_points_per_sq_mile='mean',\n            min_points_per_sq_mile='min',\n            max_points_per_sq_mile='max'\n        )\n        .round(1)\n        .reset_index()\n    )\n\n    # Total points per district\n    total_points = (\n        neighborhood_density_df\n        .groupby(council_col)[points_col]\n        .sum()\n        .reset_index(name = 'total_points')\n    )\n\n    council_stats = council_stats.merge(total_points, on = council_col)\n\n    # Find neighborhoods corresponding to min and max densities\n    min_neighborhoods = (\n        neighborhood_density_df\n        .groupby(council_col)\n        .apply(\n            lambda df: ', '.join(\n                df.loc[\n                    df[density_col] == df[density_col].min(),\n                    neighborhood_col\n                ]\n            )\n        )\n        .reset_index(name = 'min_neighborhood')\n    )\n\n    max_neighborhoods = (\n        neighborhood_density_df\n        .groupby(council_col)\n        .apply(\n            lambda df: ', '.join(\n                df.loc[\n                    df[density_col] == df[density_col].max(),\n                    neighborhood_col\n                ]\n            )\n        )\n        .reset_index(name = 'max_neighborhood')\n    )\n\n    council_stats = council_stats.merge(\n        min_neighborhoods, \n        on = council_col\n    )\n    council_stats = council_stats.merge(\n        max_neighborhoods, \n        on = council_col\n    )\n\n    # Sort by average density descending\n    council_stats = council_stats.sort_values(\n        'avg_points_per_sq_mile',\n        ascending = False\n    ).reset_index(drop = True)\n\n    return council_stats\n#______________________________________________________________________________\n\n#______________________________________________________________________________\n\ndef calculate_district_imu(\n    current_neighborhoods_gdf,\n    medically_underserved_gdf,\n    district_col = \"council_district\",\n    neighborhood_col = \"neighborhood_name\",\n    imu_col = \"med_underserv_ranking\",\n    non_residential_names = None,\n    fallback_value = 70):\n    \"\"\"\n    Calculate area-weighted Index of Medical Underservice (IMU) for each\n    district and identify the most underserved neighborhood per district.\n\n    Args:\n        current_neighborhoods_gdf: GeoDataFrame of neighborhood polygons\n        medically_underserved_gdf: GeoDataFrame of IMU areas/rankings\n        district_col: Column name for district identifier (string)\n        neighborhood_col: Column name for neighborhood name (string)\n        imu_col: Column name for medical underservice ranking (string)\n        non_residential_names: Set of neighborhood names to exclude (set)\n        fallback_value: IMU value for areas with no data (int/float)\n\n    Returns:\n        DataFrame with district-level IMU statistics\n    \"\"\"\n\n    # Filter out non-residential neighborhoods\n    if non_residential_names is not None:\n        current_neighborhoods_gdf = current_neighborhoods_gdf[\n            ~current_neighborhoods_gdf[neighborhood_col].isin(\n                non_residential_names\n            )\n        ].copy()\n\n    # Project to equal-area crs\n    neighborhoods_proj = current_neighborhoods_gdf.to_crs(epsg = 3857)\n    imu_proj = medically_underserved_gdf.to_crs(epsg = 3857)\n\n    # Spatial join to match neighborhoods with MUAPs\n    joined = gpd.sjoin(\n        neighborhoods_proj,\n        imu_proj,\n        how = \"left\",\n        predicate  =\"intersects\"\n    )\n\n    # Aggregate IMU at neighborhood level \n    # Take minimum if there's multiple overlaps\n    neighborhood_imu = (\n        joined.groupby([neighborhood_col, district_col, \"geometry\"])\n        [imu_col]\n        .min()\n        .reset_index()\n    )\n\n    # Make it a GeoDataFrame so we can compute area\n    neighborhood_imu = gpd.GeoDataFrame(\n        neighborhood_imu, \n        geometry = \"geometry\", \n        crs = current_neighborhoods_gdf.crs\n    )\n\n    # Assign fallback IMU t neighborhoods missing data\n    neighborhood_imu[imu_col] = neighborhood_imu[imu_col].fillna(\n        fallback_value\n    )\n\n    # Compute area in square miles (1 sq mi = 2,589,988.11 sq meters)\n    neighborhood_imu[\"area_sq_mi\"] = (\n        neighborhood_imu.geometry.area / 2_589_988.11\n    )\n\n    # Calculate weighted IMU (IMU score Ã— area)\n    neighborhood_imu[\"weighted_imu\"] = (\n        neighborhood_imu[imu_col] * neighborhood_imu[\"area_sq_mi\"]\n    )\n\n    # Aggregate by district\n    district_agg = (\n        neighborhood_imu\n        .groupby(district_col)\n        .agg(\n            total_weighted_imu = (\"weighted_imu\", \"sum\"),\n            total_area = (\"area_sq_mi\", \"sum\")\n        )\n        .reset_index()\n    )\n\n    # Calculate area-weighted average IMU per district\n    district_agg[\"area_weighted_IMU\"] = (\n        district_agg[\"total_weighted_imu\"] / district_agg[\"total_area\"]\n    ).round(0).astype(int)\n\n    # Find the most underserved neighborhood in each district (lowest IMU)\n    min_neighborhood = (\n        neighborhood_imu.groupby(district_col)\n        .apply(\n            lambda x: x.loc[\n                x[imu_col].idxmin(),\n                [neighborhood_col, imu_col]\n            ]\n        )\n        .reset_index()\n        .rename(columns = {\n            neighborhood_col: \"lowest_ranked_neighborhood\",\n            imu_col: \"lowest_neighborhood_IMU\"\n        })\n    )\n\n    # Merge district-level stats with most underserved neighborhoods\n    district_results = district_agg.merge(\n        min_neighborhood,\n        on = district_col\n    )\n\n    # Sort by area-weighted IMU (ascending = most underserved first)\n    district_results = district_results.sort_values(\n        \"area_weighted_IMU\"\n    ).reset_index(drop = True)\n\n    return district_results[\n        [\n            district_col,\n            \"area_weighted_IMU\",\n            \"lowest_ranked_neighborhood\",\n            \"lowest_neighborhood_IMU\"\n        ]\n    ]\n\n#______________________________________________________________________________\n"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=9091d87c-4f83-4b77-bdac-b0e7ea2c6907' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' />\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"metadata":{"deepnote_notebook_id":"6e9f4d95ff024f6f99dbeb0a5ab3fdf5","deepnote_notebook_name":"functions"},"nbformat":4,"nbformat_minor":0}