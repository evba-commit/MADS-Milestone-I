{"cells":[{"block_group":"41834990bc36465da3237ca61e8181b4","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[],"cell_id":"980181362f3c4d77b326e7ab700f9f6b","deepnote_block_group":"41834990bc36465da3237ca61e8181b4","deepnote_cell_type":"text-cell-h1","deepnote_sorting_key":"0","deepnote_source":"Functions"},"source":"# Functions"},{"block_group":"10a429269d014a79b2b83906894343e8","cell_type":"code","execution_count":null,"metadata":{"cell_id":"548fb3985c06448eb303bf142e747fb2","deepnote_block_group":"10a429269d014a79b2b83906894343e8","deepnote_cell_type":"code","deepnote_sorting_key":"1","deepnote_source":"# Load json to parse JSON text for functions module\nimport json\n\n# Load sys so Python can locate files in list of directories\nimport sys\n\n# Load os to get the current directory path\nimport os\n\n# load inspect to examine Python objects\nimport inspect\n\n# Load geopandas library to work with geoJSON files.\nimport geopandas as gpd\n\n# Load pandas library for data manipulation and analysis.\nimport pandas as pd\n\n# Load matplotlib library for data visualization.\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\n\n# Load folium to visualize geospatial data.\nimport folium\n\n# Load cmocean for colormaps.\nimport cmocean.cm as cmo\n\n# Load datetime to manipulate dates and times.\nfrom datetime import datetime\n\n# Load requests to conduct HTTP requests to an API.\nimport requests\n\n# Load time so we can time and optimize queries.\nimport time\n\n# Load Point to use in coordinate mapping.\nfrom shapely.geometry import Point\n\n\n# for cloropleth map function\nfrom branca.element import MacroElement\n\n# for cloropleth map function\nfrom jinja2 import Template"},"outputs":[],"source":"# Load json to parse JSON text for functions module\nimport json\n\n# Load sys so Python can locate files in list of directories\nimport sys\n\n# Load os to get the current directory path\nimport os\n\n# load inspect to examine Python objects\nimport inspect\n\n# Load geopandas library to work with geoJSON files.\nimport geopandas as gpd\n\n# Load pandas library for data manipulation and analysis.\nimport pandas as pd\n\n# Load matplotlib library for data visualization.\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\n\n# Load folium to visualize geospatial data.\nimport folium\n\n# Load cmocean for colormaps.\nimport cmocean.cm as cmo\n\n# Load datetime to manipulate dates and times.\nfrom datetime import datetime\n\n# Load requests to conduct HTTP requests to an API.\nimport requests\n\n# Load time so we can time and optimize queries.\nimport time\n\n# Load Point to use in coordinate mapping.\nfrom shapely.geometry import Point\n\n\n# for cloropleth map function\nfrom branca.element import MacroElement\n\n# for cloropleth map function\nfrom jinja2 import Template"},{"block_group":"03c2d7f9d4494196a77aafd5d255d54f","cell_type":"code","execution_count":null,"metadata":{"cell_id":"c6d912f9014e47c6a39b1d098f7551e1","deepnote_block_group":"03c2d7f9d4494196a77aafd5d255d54f","deepnote_cell_type":"code","deepnote_sorting_key":"2","deepnote_source":"#______________________________________________________________________________\n\ndef summarize_dataframe(df):\n    \"\"\"\n    Summarizes a DataFrame/GeoDataFrame with column-level statistics.\n    Args:\n        df: a pandas DataFrame or geopandas GeoDataFrame to summarize\n    Returns:\n        DataFrame with summary statistics for each column:\n            Type: column data type\n            Missing: count of missing values\n            Missing %: percent of missing values\n            Unique: count of unique values\n            min, max, mean: minimum, maximum, and mean (numeric columns only)\n    Raises:\n        AttributeError: If df input is not a DataFrame-like object\n        ZeroDivisionError: If DataFrame is empty\n    \"\"\"\n    summary = {\n        col: {\n            'Type': df[col].dtype,\n            'Missing': df[col].isnull().sum(),\n            'Missing %': round(df[col].isnull().sum() / len(df) * 100, 2),\n            'Unique': df[col].nunique()\n        }\n        for col in df.columns\n    }\n    \n    # Transpose summary so each row represents one column from df.\n    summary_df = pd.DataFrame(summary).T\n\n    # Grab numeric columns only (geometry is excluded automatically).\n    numeric_cols = df.select_dtypes(include='number')\n\n    # Compute summary statistics for numeric columns.\n    if not numeric_cols.empty:\n        summary_stats = numeric_cols.agg(['min', 'max', 'mean']).T.round(2)\n        summary_df = summary_df.join(summary_stats)\n\n    return summary_df\n\n#______________________________________________________________________________"},"outputs":[],"source":"#______________________________________________________________________________\n\ndef summarize_dataframe(df):\n    \"\"\"\n    Summarizes a DataFrame/GeoDataFrame with column-level statistics.\n    Args:\n        df: a pandas DataFrame or geopandas GeoDataFrame to summarize\n    Returns:\n        DataFrame with summary statistics for each column:\n            Type: column data type\n            Missing: count of missing values\n            Missing %: percent of missing values\n            Unique: count of unique values\n            min, max, mean: minimum, maximum, and mean (numeric columns only)\n    Raises:\n        AttributeError: If df input is not a DataFrame-like object\n        ZeroDivisionError: If DataFrame is empty\n    \"\"\"\n    summary = {\n        col: {\n            'Type': df[col].dtype,\n            'Missing': df[col].isnull().sum(),\n            'Missing %': round(df[col].isnull().sum() / len(df) * 100, 2),\n            'Unique': df[col].nunique()\n        }\n        for col in df.columns\n    }\n    \n    # Transpose summary so each row represents one column from df.\n    summary_df = pd.DataFrame(summary).T\n\n    # Grab numeric columns only (geometry is excluded automatically).\n    numeric_cols = df.select_dtypes(include='number')\n\n    # Compute summary statistics for numeric columns.\n    if not numeric_cols.empty:\n        summary_stats = numeric_cols.agg(['min', 'max', 'mean']).T.round(2)\n        summary_df = summary_df.join(summary_stats)\n\n    return summary_df\n\n#______________________________________________________________________________"},{"block_group":"192dc72f438146c0ac01b555ce5e3ec3","cell_type":"code","execution_count":null,"metadata":{"cell_id":"e3ebbb43d8eb42d78336cb4ab67f9b24","deepnote_block_group":"192dc72f438146c0ac01b555ce5e3ec3","deepnote_cell_type":"code","deepnote_sorting_key":"3","deepnote_source":"#______________________________________________________________________________\n\ndef group_and_sum(df, column):\n    \"\"\"\n    Groups a DataFrame/GeoDataFrame by a specified column,\n    and sums the numeric columns.\n    Args:\n        df: a pandas DataFrame or geopandas GeoDataFrame\n        column: Column name to group by (string)\n    Returns:\n        pandas DataFrame with grouped data and summed numeric values\n    Raises:\n        ValueError: If df contains no numeric columns to sum\n    \"\"\"\n\n    # Check for numeric columns before grouping.\n    numeric_cols = df.select_dtypes(include='number').columns\n    numeric_cols = [col for col in numeric_cols if col != column]\n\n    if len(numeric_cols) == 0:\n        raise ValueError(\"DataFrame contains no numeric columns to sum\")\n\n    return df.groupby(column).sum()\n\n#______________________________________________________________________________"},"outputs":[],"source":"#______________________________________________________________________________\n\ndef group_and_sum(df, column):\n    \"\"\"\n    Groups a DataFrame/GeoDataFrame by a specified column,\n    and sums the numeric columns.\n    Args:\n        df: a pandas DataFrame or geopandas GeoDataFrame\n        column: Column name to group by (string)\n    Returns:\n        pandas DataFrame with grouped data and summed numeric values\n    Raises:\n        ValueError: If df contains no numeric columns to sum\n    \"\"\"\n\n    # Check for numeric columns before grouping.\n    numeric_cols = df.select_dtypes(include='number').columns\n    numeric_cols = [col for col in numeric_cols if col != column]\n\n    if len(numeric_cols) == 0:\n        raise ValueError(\"DataFrame contains no numeric columns to sum\")\n\n    return df.groupby(column).sum()\n\n#______________________________________________________________________________"},{"block_group":"6dbe6004df7f474dbdc218e7268ecac1","cell_type":"code","execution_count":null,"metadata":{"cell_id":"8656fd3cc5d244b1be03dfb9b1faa580","deepnote_block_group":"6dbe6004df7f474dbdc218e7268ecac1","deepnote_cell_type":"code","deepnote_sorting_key":"4","deepnote_source":"#______________________________________________________________________________\n\ndef min_max(df, column):\n    \"\"\"\n    Computes the minimum and maximum values of a column.\n    Args:\n        df: a pandas DataFrame\n        column: Column name to compute min/max for (string)\n    Returns:\n        (min_value, max_value) for the specified column (tuple)\n    Raises:\n        KeyError: If the column does not exist in the DataFrame.\n    \"\"\"\n    return df[column].min(), df[column].max()\n    \n#______________________________________________________________________________"},"outputs":[],"source":"#______________________________________________________________________________\n\ndef min_max(df, column):\n    \"\"\"\n    Computes the minimum and maximum values of a column.\n    Args:\n        df: a pandas DataFrame\n        column: Column name to compute min/max for (string)\n    Returns:\n        (min_value, max_value) for the specified column (tuple)\n    Raises:\n        KeyError: If the column does not exist in the DataFrame.\n    \"\"\"\n    return df[column].min(), df[column].max()\n    \n#______________________________________________________________________________"},{"block_group":"25d044cb15364a178a14a3d79bbc3221","cell_type":"code","execution_count":null,"metadata":{"cell_id":"f06d27ae75674f3eb13b96860756b816","deepnote_block_group":"25d044cb15364a178a14a3d79bbc3221","deepnote_cell_type":"code","deepnote_sorting_key":"5","deepnote_source":"#______________________________________________________________________________\n\ndef df_to_geodataframe(df, lon_col, lat_col, crs = \"EPSG:4326\"):\n    \"\"\"\n    Convert a pandas DataFrame with lon/lat columns into a GeoDataFrame.\n    Ensures longitude and latitude columns to numeric values, drops\n    rows with missing coordinates, and creates Point geometry objects.\n    Args:\n        df: pandas DataFrame\n        lon_col: Longitude column name (string)\n        lat_col: Latitude column name (string)\n        crs: Coordinate reference system (string, default: \"EPSG:4326\")\n    Returns:\n        geopandas.GeoDataFrame with Points in specified CRS\n    \"\"\"\n\n    df = df.copy()\n\n    # Ensure latitude and longitude columns are numeric.\n    df[lat_col] = pd.to_numeric(df[lat_col], errors = \"coerce\")\n    df[lon_col] = pd.to_numeric(df[lon_col], errors = \"coerce\")\n\n    # Drop rows with missing data.\n    df = df.dropna(subset = [lon_col, lat_col])\n\n    # Create geometry object using Shapely Point.\n    df[\"geometry\"] = [Point(xy) for xy in zip(df[lon_col], df[lat_col])]\n\n    # Convert DataFrame to a GeoDataFrame.\n    gdf = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=crs)\n\n    return gdf\n\n#______________________________________________________________________________"},"outputs":[],"source":"#______________________________________________________________________________\n\ndef df_to_geodataframe(df, lon_col, lat_col, crs = \"EPSG:4326\"):\n    \"\"\"\n    Convert a pandas DataFrame with lon/lat columns into a GeoDataFrame.\n    Ensures longitude and latitude columns to numeric values, drops\n    rows with missing coordinates, and creates Point geometry objects.\n    Args:\n        df: pandas DataFrame\n        lon_col: Longitude column name (string)\n        lat_col: Latitude column name (string)\n        crs: Coordinate reference system (string, default: \"EPSG:4326\")\n    Returns:\n        geopandas.GeoDataFrame with Points in specified CRS\n    \"\"\"\n\n    df = df.copy()\n\n    # Ensure latitude and longitude columns are numeric.\n    df[lat_col] = pd.to_numeric(df[lat_col], errors = \"coerce\")\n    df[lon_col] = pd.to_numeric(df[lon_col], errors = \"coerce\")\n\n    # Drop rows with missing data.\n    df = df.dropna(subset = [lon_col, lat_col])\n\n    # Create geometry object using Shapely Point.\n    df[\"geometry\"] = [Point(xy) for xy in zip(df[lon_col], df[lat_col])]\n\n    # Convert DataFrame to a GeoDataFrame.\n    gdf = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=crs)\n\n    return gdf\n\n#______________________________________________________________________________"},{"block_group":"62e639073e104cd3a77f7f863ba590a9","cell_type":"code","execution_count":null,"metadata":{"cell_id":"3cd3b2aa8aee4a99b34571fe8de70e83","deepnote_block_group":"62e639073e104cd3a77f7f863ba590a9","deepnote_cell_type":"code","deepnote_sorting_key":"6","deepnote_source":"#______________________________________________________________________________\n\ndef create_map_orig(gdf, fields = None, title = None, color_code = None):\n    \"\"\"\n    Create an interactive folium map.\n    Centers the map of the gdf's center and handles coordinate \n    transformations. Optionally color-codes features by a specified column.\n    Args:\n        gdf: GeoDataFrame to visualize\n        fields: field names to display in the tooltip (list, default = None)\n        title: Name of map (string, default = None)\n        color_code: Column name for color coding features (string, \n        default = None)\n    Returns:\n        folium.Map object with the GeoDataFrame layer added\n    \"\"\"\n\n    # Make a copy to avoid modifying the original GeoDataFrame.\n    gdf = gdf.copy()\n    \n    # Convert datetime columns to strings for JSON serialization.\n    datetime_cols = gdf.select_dtypes(\n        include = ['datetime64', 'datetime']\n        ).columns\n    for col in datetime_cols:\n        gdf[col] = gdf[col].astype(str)\n\n    # Calculate center based on CRS.\n    # If already in geographic crs, then\n    # project crs temporarily for centroid calculation.\n    if gdf.crs and gdf.crs.is_geographic:\n        # Use the UTM zone 17N for Detroit area.\n        gdf_projected = gdf.to_crs(epsg = 32617)\n        # Calculate center and project back to geographic.\n        center = gdf_projected.geometry.centroid.to_crs(epsg = 4326)\n    else:\n        center = gdf.geometry.centroid.to_crs(epsg = 4326)\n\n    # Calculate center\n    lat = center.y.mean()\n    lon = center.x.mean()\n\n    # Convert the crs to latitude/longitude for folium mapping.\n    gdf = gdf.to_crs(epsg = 4326)\n\n    # Create a centered base map with zoom level of 11.\n    map = folium.Map(\n        location = [lat, lon],\n        zoom_start = 11\n        )\n\n    # Configure styling based on color_code parameter.\n    if color_code:\n        # Get unique values and generate colors dynamically.\n        unique_values = gdf[color_code].unique()\n        num_colors = len(unique_values)\n        # Choose colormap based on number of categories.\n        if num_colors <= 10:\n            cmap = plt.cm.get_cmap('tab10')\n        elif num_colors <= 20:\n            cmap = plt.cm.get_cmap('tab20')\n        else:\n            cmap = plt.cm.get_cmap('hsv')\n        # Generate colors.\n        colors = [mcolors.rgb2hex(\n            cmap(i / num_colors)\n            ) \n            for i in range(num_colors)\n            ]\n        # Create color map dictionary.\n        color_map = {val: colors[i] for i, val in enumerate(unique_values)}\n        # Define style function with color coding.\n        style_function = lambda x: {\n            \"fillColor\": color_map.get(x['properties'][color_code], 'gray'),\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.7\n        }\n\n    # If color code is not specified, use one color.  \n    else:\n        # Define style function with single color.\n        style_function = lambda x: {\n            \"fillColor\": \"blue\",\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.5\n        }\n    \n    # Add GeoJSON layer to map.\n    folium.GeoJson(\n        gdf,\n        name = title,\n        style_function = style_function,\n        tooltip = folium.GeoJsonTooltip(\n            fields = fields\n            ) \n            if fields \n            else None\n    ).add_to(map)\n    \n    return map\n\n#______________________________________________________________________________"},"outputs":[],"source":"#______________________________________________________________________________\n\ndef create_map_orig(gdf, fields = None, title = None, color_code = None):\n    \"\"\"\n    Create an interactive folium map.\n    Centers the map of the gdf's center and handles coordinate \n    transformations. Optionally color-codes features by a specified column.\n    Args:\n        gdf: GeoDataFrame to visualize\n        fields: field names to display in the tooltip (list, default = None)\n        title: Name of map (string, default = None)\n        color_code: Column name for color coding features (string, \n        default = None)\n    Returns:\n        folium.Map object with the GeoDataFrame layer added\n    \"\"\"\n\n    # Make a copy to avoid modifying the original GeoDataFrame.\n    gdf = gdf.copy()\n    \n    # Convert datetime columns to strings for JSON serialization.\n    datetime_cols = gdf.select_dtypes(\n        include = ['datetime64', 'datetime']\n        ).columns\n    for col in datetime_cols:\n        gdf[col] = gdf[col].astype(str)\n\n    # Calculate center based on CRS.\n    # If already in geographic crs, then\n    # project crs temporarily for centroid calculation.\n    if gdf.crs and gdf.crs.is_geographic:\n        # Use the UTM zone 17N for Detroit area.\n        gdf_projected = gdf.to_crs(epsg = 32617)\n        # Calculate center and project back to geographic.\n        center = gdf_projected.geometry.centroid.to_crs(epsg = 4326)\n    else:\n        center = gdf.geometry.centroid.to_crs(epsg = 4326)\n\n    # Calculate center\n    lat = center.y.mean()\n    lon = center.x.mean()\n\n    # Convert the crs to latitude/longitude for folium mapping.\n    gdf = gdf.to_crs(epsg = 4326)\n\n    # Create a centered base map with zoom level of 11.\n    map = folium.Map(\n        location = [lat, lon],\n        zoom_start = 11\n        )\n\n    # Configure styling based on color_code parameter.\n    if color_code:\n        # Get unique values and generate colors dynamically.\n        unique_values = gdf[color_code].unique()\n        num_colors = len(unique_values)\n        # Choose colormap based on number of categories.\n        if num_colors <= 10:\n            cmap = plt.cm.get_cmap('tab10')\n        elif num_colors <= 20:\n            cmap = plt.cm.get_cmap('tab20')\n        else:\n            cmap = plt.cm.get_cmap('hsv')\n        # Generate colors.\n        colors = [mcolors.rgb2hex(\n            cmap(i / num_colors)\n            ) \n            for i in range(num_colors)\n            ]\n        # Create color map dictionary.\n        color_map = {val: colors[i] for i, val in enumerate(unique_values)}\n        # Define style function with color coding.\n        style_function = lambda x: {\n            \"fillColor\": color_map.get(x['properties'][color_code], 'gray'),\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.7\n        }\n\n    # If color code is not specified, use one color.  \n    else:\n        # Define style function with single color.\n        style_function = lambda x: {\n            \"fillColor\": \"blue\",\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.5\n        }\n    \n    # Add GeoJSON layer to map.\n    folium.GeoJson(\n        gdf,\n        name = title,\n        style_function = style_function,\n        tooltip = folium.GeoJsonTooltip(\n            fields = fields\n            ) \n            if fields \n            else None\n    ).add_to(map)\n    \n    return map\n\n#______________________________________________________________________________"},{"block_group":"cd0307eb0fb34b6d99714279f0c84c78","cell_type":"code","execution_count":null,"metadata":{"cell_id":"44a7fa7bc75e45be97ea99d54440edad","deepnote_block_group":"cd0307eb0fb34b6d99714279f0c84c78","deepnote_cell_type":"code","deepnote_sorting_key":"7","deepnote_source":"#______________________________________________________________________________\n\ndef create_map(gdf, fields = None, title = None, color_code = None):\n    \"\"\"\n    Create an interactive folium map from a GeoDataFrame.\n    Centers the map on the GeoDataFrame's centroid and uses a muted \n    cmocean color scheme for better visibility.\n    Args:\n        gdf: geopandas.GeoDataFrame to visualize\n        fields: Field names to display in tooltip (list, default = None)\n        title: Name of the map layer (string, default = None)\n        color_code: column name for color coding features \n        (string, default = None)\n    Returns:\n        folium.Map object with the GeoDataFrame layer added\n    \"\"\"\n\n    gdf = gdf.copy()\n    \n    # Convert datetime columns to strings for JSON serialization\n    datetime_cols = gdf.select_dtypes(\n        include = ['datetime64', 'datetime']\n        ).columns\n    for col in datetime_cols:\n        gdf[col] = gdf[col].astype(str)\n\n    # Calculate center based on CRS\n    # If already in geographic CRS, project temporarily for accurate centroid\n    if gdf.crs and gdf.crs.is_geographic:\n        # Use UTM zone 17N for Detroit area\n        gdf_projected = gdf.to_crs(epsg = 32617)\n        # Project back to EPSG:4326 immediately\n        center = gdf_projected.geometry.centroid.to_crs(epsg = 4326)\n    else:\n        center = gdf.geometry.centroid.to_crs(epsg = 4326)\n\n    # Calculate center coordinates\n    lat = center.y.mean()\n    lon = center.x.mean()\n\n    # convert to WGS84 for mapping\n    gdf = gdf.to_crs(epsg = 4326)\n\n    # Create base map\n    m = folium.Map(location = [lat, lon], zoom_start = 11)\n\n    # Configure color.\n    # Configure styling based on color_code parameter\n    if color_code:\n        unique_values = gdf[color_code].unique()\n        num_colors = len(unique_values)\n\n        # Use cmocean \"phase\" colormap.\n        cmap = cmo.phase\n\n        # Generate colors for discrete categories.\n        colors = [mcolors.rgb2hex(\n            cmap(i / max(num_colors-1, 1))\n            )\n            for i in range(num_colors)\n            ]\n        color_map = {val: colors[i] for i, val in enumerate(unique_values)}\n\n        # Define style function with color coding.\n        style_function = lambda x: {\n            \"fillColor\": color_map.get(x['properties'][color_code], 'gray'),\n            \"color\": \"gray\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.35\n        }\n\n    else:\n        # Define style function with single color\n        style_function = lambda x: {\n            \"fillColor\": \"blue\",\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.35\n        }\n    \n    # Add GeoJSON layer to map.\n    folium.GeoJson(\n        gdf,\n        name = title,\n        style_function = style_function,\n        tooltip = folium.GeoJsonTooltip(fields = fields) if fields else None\n    ).add_to(m)\n    \n    return m\n\n#______________________________________________________________________________"},"outputs":[],"source":"#______________________________________________________________________________\n\ndef create_map(gdf, fields = None, title = None, color_code = None):\n    \"\"\"\n    Create an interactive folium map from a GeoDataFrame.\n    Centers the map on the GeoDataFrame's centroid and uses a muted \n    cmocean color scheme for better visibility.\n    Args:\n        gdf: geopandas.GeoDataFrame to visualize\n        fields: Field names to display in tooltip (list, default = None)\n        title: Name of the map layer (string, default = None)\n        color_code: column name for color coding features \n        (string, default = None)\n    Returns:\n        folium.Map object with the GeoDataFrame layer added\n    \"\"\"\n\n    gdf = gdf.copy()\n    \n    # Convert datetime columns to strings for JSON serialization\n    datetime_cols = gdf.select_dtypes(\n        include = ['datetime64', 'datetime']\n        ).columns\n    for col in datetime_cols:\n        gdf[col] = gdf[col].astype(str)\n\n    # Calculate center based on CRS\n    # If already in geographic CRS, project temporarily for accurate centroid\n    if gdf.crs and gdf.crs.is_geographic:\n        # Use UTM zone 17N for Detroit area\n        gdf_projected = gdf.to_crs(epsg = 32617)\n        # Project back to EPSG:4326 immediately\n        center = gdf_projected.geometry.centroid.to_crs(epsg = 4326)\n    else:\n        center = gdf.geometry.centroid.to_crs(epsg = 4326)\n\n    # Calculate center coordinates\n    lat = center.y.mean()\n    lon = center.x.mean()\n\n    # convert to WGS84 for mapping\n    gdf = gdf.to_crs(epsg = 4326)\n\n    # Create base map\n    m = folium.Map(location = [lat, lon], zoom_start = 11)\n\n    # Configure color.\n    # Configure styling based on color_code parameter\n    if color_code:\n        unique_values = gdf[color_code].unique()\n        num_colors = len(unique_values)\n\n        # Use cmocean \"phase\" colormap.\n        cmap = cmo.phase\n\n        # Generate colors for discrete categories.\n        colors = [mcolors.rgb2hex(\n            cmap(i / max(num_colors-1, 1))\n            )\n            for i in range(num_colors)\n            ]\n        color_map = {val: colors[i] for i, val in enumerate(unique_values)}\n\n        # Define style function with color coding.\n        style_function = lambda x: {\n            \"fillColor\": color_map.get(x['properties'][color_code], 'gray'),\n            \"color\": \"gray\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.35\n        }\n\n    else:\n        # Define style function with single color\n        style_function = lambda x: {\n            \"fillColor\": \"blue\",\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.35\n        }\n    \n    # Add GeoJSON layer to map.\n    folium.GeoJson(\n        gdf,\n        name = title,\n        style_function = style_function,\n        tooltip = folium.GeoJsonTooltip(fields = fields) if fields else None\n    ).add_to(m)\n    \n    return m\n\n#______________________________________________________________________________"},{"block_group":"82021fcf4a9c44e98710d090aa161f9f","cell_type":"code","execution_count":null,"metadata":{"cell_id":"5dda1f0f820f429ebf74a5ca4001b2ff","deepnote_block_group":"82021fcf4a9c44e98710d090aa161f9f","deepnote_cell_type":"code","deepnote_sorting_key":"8","deepnote_source":"#______________________________________________________________________________\ndef points_in_neighborhood_map(\n    point_layers,\n    neighborhoods_gdf,\n    council_col = \"council_district\",\n    neighborhood_col = \"neighborhood_name\",\n    point_info_col = None,\n    point_base_color = \"blue\",\n    ranking_col = \"med_underserv_ranking\",\n    start_zoom = 12,\n    point_radius = 4,\n    point_opacity= 0.8,\n    title = None,\n    subtitle = None\n):\n    \"\"\"\n    Create an interactive folium map that displays neighborhood polygons\n    color-coded by council-district, and overlays point layers showing \n    contextual information including council_district, neighborhood, etc.\n    Each point's shade corresponds to the ranking column's value.\n    \n    Args:\n        point_layers: Dictionary of point layers to overlay \n            {'name': GeoDataFrame}\n        neighborhoods_gdf: GeoDataFrame containing Neighborhood polygons \n            and council district column (GeoDataFrame)\n        council_col: name of council district column (string)\n        neighborhood_col: Name of neighborhood column (string)\n        point_info_col: Column in point layer to display in tooltip (string, \n            optional)\n        point_base_color: Base color for points (string)\n        ranking_col: Column to dertermine point shade where lower values \n            are darker, higher values are lighter (string)\n        start_zoom: Initial zoom level (integer)\n        point_radius: Radius of point markers (integer)\n        point_opacity: Opacity of point markers (0-1) (float)\n        title: Map title displayed in top-left corner (string)\n        subtitle: Subtitle displayed below title (string)\n    \n    Returns:\n        folium.Map\n    \"\"\"\n\n    # Normalize crs and ensure all geometries use WGS84 for web mapping\n    neighborhoods = neighborhoods_gdf.to_crs(epsg = 4326)\n    normalized_points = {}\n    all_points = []\n\n    # Reproject each point layer\n    for name, gdf in point_layers.items():\n        gdf = gdf.to_crs(epsg = 4326)\n        normalized_points[name] = gdf\n        all_points.append(gdf)\n\n    # Initialize the map\n    combined_points = gpd.GeoDataFrame(\n        pd.concat(all_points, ignore_index = True), \n        crs = \"EPSG:4326\"\n    )\n    # Calculate centroid of all points\n    center_lat = combined_points.geometry.y.mean()\n    center_lon = combined_points.geometry.x.mean()\n    m = folium.Map(\n        location = [center_lat, center_lon], \n        zoom_start = start_zoom\n    )\n\n    # Add title block to top left if provided\n    if title:\n        title_html = f\"\"\"\n        <div style=\"\n            position: fixed;\n            top: 15px;\n            left: 15px;\n            z-index: 9999;\n            background-color: white;\n            padding: 8px 12px;\n            border-radius: 6px;\n            box-shadow: 0 2px 6px rgba(0,0,0,0.2);\n            font-family: Arial, sans-serif;\n        \">\n            <div style=\"font-size: 14px; font-weight: bold;\">\n                {title}\n            </div>\n            {f'<div style=\"font-size: 12px; color: gray;\">{subtitle}</div>' \n             if subtitle else ''}\n        </div>\n        \"\"\"\n        m.get_root().html.add_child(folium.Element(title_html))\n\n    # Generate distinct colors to color code each council district\n    unique_vals = neighborhoods[council_col].dropna().unique()\n    num_colors = len(unique_vals)\n    cmap = cmo.phase\n    colors = [\n        mcolors.rgb2hex(cmap(i / max(num_colors - 1, 1))) \n        for i in range(num_colors)\n    ]\n    color_map = {val: colors[i] for i, val in enumerate(unique_vals)}\n\n    # Add neighborhood polygons as GeoJSON layer\n    folium.GeoJson(\n        neighborhoods,\n        name=\"Neighborhoods\",\n        style_function = lambda feature: {\n            \"fillColor\": color_map.get(\n                feature[\"properties\"].get(council_col), \"gray\"\n            ),\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.35,\n        },\n        tooltip = folium.GeoJsonTooltip(\n            fields = [council_col, neighborhood_col],\n            aliases = [\"Council District:\", \"Neighborhood:\"],\n        ),\n    ).add_to(m)\n\n    # Set up ranking-based color gradient\n    base_rgb = mcolors.to_rgb(point_base_color)\n\n    # Determine global min/max rankings for consistent shading\n    ranking_exists = any(\n        ranking_col in gdf.columns for gdf in normalized_points.values()\n    )\n    if ranking_exists:\n        all_ranks = pd.concat([\n            gdf[ranking_col] for gdf in normalized_points.values() \n            if ranking_col in gdf.columns\n        ])\n        rank_min = all_ranks.min()\n        rank_max = all_ranks.max()\n\n    # Add each point layer through spatial join with neighborhoods\n    for layer_name, points_gdf in normalized_points.items():\n        # Spacial join to get neighborhood attributes\n        joined = gpd.sjoin(\n            points_gdf,\n            neighborhoods[[neighborhood_col, council_col, \"geometry\"]],\n            how = \"left\",\n            predicate = \"within\"\n        )\n\n        # Add individual point markers\n        for _, row in joined.iterrows():\n            # Create tooltip content\n            tooltip_text = (\n                f\"Neighborhood: {row.get(neighborhood_col, 'N/A')}<br>\"\n                f\"Council District: {row.get(council_col, 'N/A')}<br>\"\n            )\n            if point_info_col:\n                tooltip_text += (\n                    f\"{point_info_col}: {row.get(point_info_col, 'N/A')}\"\n                )\n\n            # Calculate point shade based on ranking column\n            if (ranking_exists and ranking_col in row and \n                    pd.notnull(row.get(ranking_col))):\n                # Normalize ranking to range from 0 to 1\n                rank_range = max(rank_max - rank_min, 1e-6)\n                norm_rank = (row[ranking_col] - rank_min) / rank_range\n                # Lower ranking is darker, higher is lighter\n                color_rgb = tuple([\n                    base_rgb[i] * (1 - 0.5 * norm_rank) \n                    for i in range(3)\n                ])\n                fill_color = mcolors.to_hex(color_rgb)\n            else:\n                fill_color = point_base_color\n\n            folium.CircleMarker(\n                location = [row.geometry.y, row.geometry.x],\n                radius = point_radius,\n                color = fill_color,\n                fill = True,\n                fill_color = fill_color,\n                fill_opacity = point_opacity,\n                tooltip = tooltip_text,\n            ).add_to(m)\n\n    return m\n\n#______________________________________________________________________________"},"outputs":[],"source":"#______________________________________________________________________________\ndef points_in_neighborhood_map(\n    point_layers,\n    neighborhoods_gdf,\n    council_col = \"council_district\",\n    neighborhood_col = \"neighborhood_name\",\n    point_info_col = None,\n    point_base_color = \"blue\",\n    ranking_col = \"med_underserv_ranking\",\n    start_zoom = 12,\n    point_radius = 4,\n    point_opacity= 0.8,\n    title = None,\n    subtitle = None\n):\n    \"\"\"\n    Create an interactive folium map that displays neighborhood polygons\n    color-coded by council-district, and overlays point layers showing \n    contextual information including council_district, neighborhood, etc.\n    Each point's shade corresponds to the ranking column's value.\n    \n    Args:\n        point_layers: Dictionary of point layers to overlay \n            {'name': GeoDataFrame}\n        neighborhoods_gdf: GeoDataFrame containing Neighborhood polygons \n            and council district column (GeoDataFrame)\n        council_col: name of council district column (string)\n        neighborhood_col: Name of neighborhood column (string)\n        point_info_col: Column in point layer to display in tooltip (string, \n            optional)\n        point_base_color: Base color for points (string)\n        ranking_col: Column to dertermine point shade where lower values \n            are darker, higher values are lighter (string)\n        start_zoom: Initial zoom level (integer)\n        point_radius: Radius of point markers (integer)\n        point_opacity: Opacity of point markers (0-1) (float)\n        title: Map title displayed in top-left corner (string)\n        subtitle: Subtitle displayed below title (string)\n    \n    Returns:\n        folium.Map\n    \"\"\"\n\n    # Normalize crs and ensure all geometries use WGS84 for web mapping\n    neighborhoods = neighborhoods_gdf.to_crs(epsg = 4326)\n    normalized_points = {}\n    all_points = []\n\n    # Reproject each point layer\n    for name, gdf in point_layers.items():\n        gdf = gdf.to_crs(epsg = 4326)\n        normalized_points[name] = gdf\n        all_points.append(gdf)\n\n    # Initialize the map\n    combined_points = gpd.GeoDataFrame(\n        pd.concat(all_points, ignore_index = True), \n        crs = \"EPSG:4326\"\n    )\n    # Calculate centroid of all points\n    center_lat = combined_points.geometry.y.mean()\n    center_lon = combined_points.geometry.x.mean()\n    m = folium.Map(\n        location = [center_lat, center_lon], \n        zoom_start = start_zoom\n    )\n\n    # Add title block to top left if provided\n    if title:\n        title_html = f\"\"\"\n        <div style=\"\n            position: fixed;\n            top: 15px;\n            left: 15px;\n            z-index: 9999;\n            background-color: white;\n            padding: 8px 12px;\n            border-radius: 6px;\n            box-shadow: 0 2px 6px rgba(0,0,0,0.2);\n            font-family: Arial, sans-serif;\n        \">\n            <div style=\"font-size: 14px; font-weight: bold;\">\n                {title}\n            </div>\n            {f'<div style=\"font-size: 12px; color: gray;\">{subtitle}</div>' \n             if subtitle else ''}\n        </div>\n        \"\"\"\n        m.get_root().html.add_child(folium.Element(title_html))\n\n    # Generate distinct colors to color code each council district\n    unique_vals = neighborhoods[council_col].dropna().unique()\n    num_colors = len(unique_vals)\n    cmap = cmo.phase\n    colors = [\n        mcolors.rgb2hex(cmap(i / max(num_colors - 1, 1))) \n        for i in range(num_colors)\n    ]\n    color_map = {val: colors[i] for i, val in enumerate(unique_vals)}\n\n    # Add neighborhood polygons as GeoJSON layer\n    folium.GeoJson(\n        neighborhoods,\n        name=\"Neighborhoods\",\n        style_function = lambda feature: {\n            \"fillColor\": color_map.get(\n                feature[\"properties\"].get(council_col), \"gray\"\n            ),\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.35,\n        },\n        tooltip = folium.GeoJsonTooltip(\n            fields = [council_col, neighborhood_col],\n            aliases = [\"Council District:\", \"Neighborhood:\"],\n        ),\n    ).add_to(m)\n\n    # Set up ranking-based color gradient\n    base_rgb = mcolors.to_rgb(point_base_color)\n\n    # Determine global min/max rankings for consistent shading\n    ranking_exists = any(\n        ranking_col in gdf.columns for gdf in normalized_points.values()\n    )\n    if ranking_exists:\n        all_ranks = pd.concat([\n            gdf[ranking_col] for gdf in normalized_points.values() \n            if ranking_col in gdf.columns\n        ])\n        rank_min = all_ranks.min()\n        rank_max = all_ranks.max()\n\n    # Add each point layer through spatial join with neighborhoods\n    for layer_name, points_gdf in normalized_points.items():\n        # Spacial join to get neighborhood attributes\n        joined = gpd.sjoin(\n            points_gdf,\n            neighborhoods[[neighborhood_col, council_col, \"geometry\"]],\n            how = \"left\",\n            predicate = \"within\"\n        )\n\n        # Add individual point markers\n        for _, row in joined.iterrows():\n            # Create tooltip content\n            tooltip_text = (\n                f\"Neighborhood: {row.get(neighborhood_col, 'N/A')}<br>\"\n                f\"Council District: {row.get(council_col, 'N/A')}<br>\"\n            )\n            if point_info_col:\n                tooltip_text += (\n                    f\"{point_info_col}: {row.get(point_info_col, 'N/A')}\"\n                )\n\n            # Calculate point shade based on ranking column\n            if (ranking_exists and ranking_col in row and \n                    pd.notnull(row.get(ranking_col))):\n                # Normalize ranking to range from 0 to 1\n                rank_range = max(rank_max - rank_min, 1e-6)\n                norm_rank = (row[ranking_col] - rank_min) / rank_range\n                # Lower ranking is darker, higher is lighter\n                color_rgb = tuple([\n                    base_rgb[i] * (1 - 0.5 * norm_rank) \n                    for i in range(3)\n                ])\n                fill_color = mcolors.to_hex(color_rgb)\n            else:\n                fill_color = point_base_color\n\n            folium.CircleMarker(\n                location = [row.geometry.y, row.geometry.x],\n                radius = point_radius,\n                color = fill_color,\n                fill = True,\n                fill_color = fill_color,\n                fill_opacity = point_opacity,\n                tooltip = tooltip_text,\n            ).add_to(m)\n\n    return m\n\n#______________________________________________________________________________"},{"block_group":"89d8b0b0ef2e44f58c8e79ebb2429022","cell_type":"code","execution_count":null,"metadata":{"cell_id":"ea0dd2a25d744220ad7dd603e18478ac","deepnote_block_group":"89d8b0b0ef2e44f58c8e79ebb2429022","deepnote_cell_type":"code","deepnote_sorting_key":"9","deepnote_source":"#______________________________________________________________________________\n\ndef assign_points_to_neighborhood(\n    points_gdf, neighborhoods_gdf, neighborhood_cols):\n    \"\"\"\n    Performs a spatial join to determine which neighborhood polygon each point\n    falls into, then attaches neighborhood information to each point.\n\n    Args:\n        points_gdf: Point locations (GeoDataFrame)\n        neighborhoods_gdf: Neighborhood polygons (GeoDataFrame)\n        neighborhood_cols: Columns from neighborhoods_gdf to attach (list[str])\n\n    Returns: \n        GeoDataFrame: a copy of points_gdf with additional columns from \n        neighborhood_cols. Retains all original points (left join).\n    \"\"\"\n\n    # Make a copy to avoid modifying original.\n    points = points_gdf.copy()\n\n    # Automatically set crs to points.crs if they differ.\n    if neighborhoods_gdf.crs != points.crs:\n        neighborhoods_gdf = neighborhoods_gdf.to_crs(points.crs)\n\n    # Left join neighborhoods to points\n    joined = gpd.sjoin(\n        points,\n        neighborhoods_gdf[['geometry'] + neighborhood_cols],\n        how = 'left',\n        predicate = 'within'\n    )\n\n    # drop spatial join helper column\n    joined = joined.drop(columns = 'index_right')\n\n    return joined\n\n#______________________________________________________________________________"},"outputs":[],"source":"#______________________________________________________________________________\n\ndef assign_points_to_neighborhood(\n    points_gdf, neighborhoods_gdf, neighborhood_cols):\n    \"\"\"\n    Performs a spatial join to determine which neighborhood polygon each point\n    falls into, then attaches neighborhood information to each point.\n\n    Args:\n        points_gdf: Point locations (GeoDataFrame)\n        neighborhoods_gdf: Neighborhood polygons (GeoDataFrame)\n        neighborhood_cols: Columns from neighborhoods_gdf to attach (list[str])\n\n    Returns: \n        GeoDataFrame: a copy of points_gdf with additional columns from \n        neighborhood_cols. Retains all original points (left join).\n    \"\"\"\n\n    # Make a copy to avoid modifying original.\n    points = points_gdf.copy()\n\n    # Automatically set crs to points.crs if they differ.\n    if neighborhoods_gdf.crs != points.crs:\n        neighborhoods_gdf = neighborhoods_gdf.to_crs(points.crs)\n\n    # Left join neighborhoods to points\n    joined = gpd.sjoin(\n        points,\n        neighborhoods_gdf[['geometry'] + neighborhood_cols],\n        how = 'left',\n        predicate = 'within'\n    )\n\n    # drop spatial join helper column\n    joined = joined.drop(columns = 'index_right')\n\n    return joined\n\n#______________________________________________________________________________"},{"block_group":"31200e979fa449ee9363ead791909e23","cell_type":"code","execution_count":null,"metadata":{"cell_id":"9fd2f6816a7047d4a1ac2852d7252cde","deepnote_block_group":"31200e979fa449ee9363ead791909e23","deepnote_cell_type":"code","deepnote_sorting_key":"10","deepnote_source":"#______________________________________________________________________________\ndef density_per_neighborhood(\n    points_gdf, \n    neighborhoods_gdf,\n    neighborhood_col = 'Current_Neighborhoods',\n    neighborhood_name_col = 'neighborhood_name',\n    council_col = 'council_district'):\n    \"\"\"\n    Calculate points per square mile for neighborhoods and attach council \n    district, including raw point counts.\n\n    Returns a DataFrame with columns:\n    [neighborhood_col, points, points_per_sq_mile, council_col]\n    \"\"\"\n\n    # Count points per neighborhood (raw counts)\n    counts = (\n        points_gdf\n        .groupby(neighborhood_col)\n        .size()\n        .rename('points')  # store raw counts\n        .reset_index()\n    )\n\n    # Calculate neighborhood areas in square miles (crs in feet)\n    neighborhoods_gdf = neighborhoods_gdf.to_crs(epsg = 2263) \n    neighborhoods_gdf['area_sq_miles'] = (\n        neighborhoods_gdf.geometry.area / (5280 ** 2)\n    )\n\n    # Merge in council district and area \n    merged = counts.merge(\n        neighborhoods_gdf[\n            [neighborhood_name_col, council_col, 'area_sq_miles']\n        ],\n        left_on = neighborhood_col,\n        right_on = neighborhood_name_col,\n        how = 'left'\n    )\n\n    # Calculate points per square mile and round to nearest tenth\n    merged['points_per_sq_mile'] = (\n        (merged['points'] / merged['area_sq_miles']).round(1)\n        )\n\n    # Keep desired columns\n    merged = merged[\n        [neighborhood_col, 'points', 'points_per_sq_mile', council_col]\n    ]\n\n    # Sort by density descending\n    merged = merged.sort_values(\n        'points_per_sq_mile', \n        ascending = False\n        ).reset_index(drop = True)\n\n    return merged\n\n#______________________________________________________________________________"},"outputs":[],"source":"#______________________________________________________________________________\ndef density_per_neighborhood(\n    points_gdf, \n    neighborhoods_gdf,\n    neighborhood_col = 'Current_Neighborhoods',\n    neighborhood_name_col = 'neighborhood_name',\n    council_col = 'council_district'):\n    \"\"\"\n    Calculate points per square mile for neighborhoods and attach council \n    district, including raw point counts.\n\n    Returns a DataFrame with columns:\n    [neighborhood_col, points, points_per_sq_mile, council_col]\n    \"\"\"\n\n    # Count points per neighborhood (raw counts)\n    counts = (\n        points_gdf\n        .groupby(neighborhood_col)\n        .size()\n        .rename('points')  # store raw counts\n        .reset_index()\n    )\n\n    # Calculate neighborhood areas in square miles (crs in feet)\n    neighborhoods_gdf = neighborhoods_gdf.to_crs(epsg = 2263) \n    neighborhoods_gdf['area_sq_miles'] = (\n        neighborhoods_gdf.geometry.area / (5280 ** 2)\n    )\n\n    # Merge in council district and area \n    merged = counts.merge(\n        neighborhoods_gdf[\n            [neighborhood_name_col, council_col, 'area_sq_miles']\n        ],\n        left_on = neighborhood_col,\n        right_on = neighborhood_name_col,\n        how = 'left'\n    )\n\n    # Calculate points per square mile and round to nearest tenth\n    merged['points_per_sq_mile'] = (\n        (merged['points'] / merged['area_sq_miles']).round(1)\n        )\n\n    # Keep desired columns\n    merged = merged[\n        [neighborhood_col, 'points', 'points_per_sq_mile', council_col]\n    ]\n\n    # Sort by density descending\n    merged = merged.sort_values(\n        'points_per_sq_mile', \n        ascending = False\n        ).reset_index(drop = True)\n\n    return merged\n\n#______________________________________________________________________________"},{"block_group":"25ac0e7100a54b71976ab0e0c03f2daa","cell_type":"code","execution_count":null,"metadata":{"cell_id":"1a0c0e7ade3e4e0e88fc3d87f3496aab","deepnote_block_group":"25ac0e7100a54b71976ab0e0c03f2daa","deepnote_cell_type":"code","deepnote_sorting_key":"11","deepnote_source":"# Flag Medically Underserved neighborhoods that have many Green Light Locations\ndef flag_underserved_with_green_lights(med_counts, green_counts, threshold=5):\n    \"\"\"\n    Identify neighborhoods that are medically underserved but have >= threshold green lights.\n    \"\"\"\n    merged = med_counts.merge(green_counts, on='City Neighborhoods', how='left', suffixes=('_med', '_green'))\n    merged['count_green'] = merged['count_green'].fillna(0)\n    merged['flag_many_green'] = merged['count_green'] >= threshold\n    return merged"},"outputs":[],"source":"# Flag Medically Underserved neighborhoods that have many Green Light Locations\ndef flag_underserved_with_green_lights(med_counts, green_counts, threshold=5):\n    \"\"\"\n    Identify neighborhoods that are medically underserved but have >= threshold green lights.\n    \"\"\"\n    merged = med_counts.merge(green_counts, on='City Neighborhoods', how='left', suffixes=('_med', '_green'))\n    merged['count_green'] = merged['count_green'].fillna(0)\n    merged['flag_many_green'] = merged['count_green'] >= threshold\n    return merged"},{"block_group":"502da78367af4563854b676fad0e34ed","cell_type":"code","execution_count":null,"metadata":{"cell_id":"bf34f7b0bc5b424ab982e7032cc3a615","deepnote_block_group":"502da78367af4563854b676fad0e34ed","deepnote_cell_type":"code","deepnote_sorting_key":"12","deepnote_source":"# Display a chloropleth map to show num of service requests \n# for each neighborhood and council district\ndef neighborhood_choropleth_map(\n    neighborhoods_gdf: gpd.GeoDataFrame,\n    value_col: str = \"request_count\",\n    council_col: str = \"council_district\",\n    neighborhood_col: str = \"neighborhood_name\",\n    start_zoom: int = 12,\n    title: str = None,\n    subtitle: str = None\n):\n    \"\"\"\n    Display a choropleth map of neighborhoods colored by council district,\n    with shading based on request count and hover tooltips.\n    Optional fixed title and subtitle in the top-left corner.\n\n    Args:\n        neighborhoods_gdf: Neighborhood polygons with request counts (GeoDataFrame)\n        value_col: Column with aggregated request counts (string)\n        council_col: Council district column (str)\n        neighborhood_col: Neighborhood name column (str)\n        start_zoom: Initial zoom level (int)\n        title: Optional map title (str)\n        subtitle: Optional map subtitle (str)\n\n    Returns:\n        folium.Map\n    \"\"\"\n\n    # ---- CRS normalization ----\n    neighborhoods = neighborhoods_gdf.to_crs(epsg=4326)\n\n    # ---- Fill missing values with 0 to include neighborhoods with no requests ----\n    neighborhoods[value_col] = neighborhoods[value_col].fillna(0)\n\n    # ---- Map center ----\n    center_lat = neighborhoods.geometry.centroid.y.mean()\n    center_lon = neighborhoods.geometry.centroid.x.mean()\n    m = folium.Map(location=[center_lat, center_lon], zoom_start=start_zoom)\n\n    # ---- Add fixed top-left title/subtitle ----\n    if title or subtitle:\n        html_content = \"\"\n        if title:\n            html_content += f\"<h4 style='margin:0'>{title}</h4>\"\n        if subtitle:\n            html_content += f\"<p style='margin:0'>{subtitle}</p>\"\n\n        template = f\"\"\"\n        <div style=\"\n            position: fixed;\n            top: 10px;\n            left: 10px;\n            z-index: 9999;\n            background-color: rgba(255,255,255,0.85);\n            padding: 5px 10px;\n            border-radius: 5px;\n            font-family: sans-serif;\n        \">\n            {html_content}\n        </div>\n        \"\"\"\n        macro = MacroElement()\n        macro._template = Template(template)\n        m.get_root().add_child(macro)\n\n    # ---- Council district base colors ----\n    unique_vals = neighborhoods[council_col].dropna().unique()\n    num_colors = len(unique_vals)\n    cmap = cmo.phase\n    colors = [\n        mcolors.rgb2hex(cmap(i / max(num_colors - 1, 1)))\n        for i in range(num_colors)\n    ]\n    council_color_map = {val: colors[i] for i, val in enumerate(unique_vals)}\n\n    # ---- Normalize request counts for shading ----\n    vmin = neighborhoods[value_col].min()\n    vmax = neighborhoods[value_col].max()\n\n    def style_function(feature):\n        props = feature[\"properties\"]\n        council = props.get(council_col)\n        count = props.get(value_col)\n\n        base_color = council_color_map.get(council, \"#cccccc\")\n\n        if count is not None and vmax > vmin:\n            norm = (count - vmin) / (vmax - vmin)\n            base_rgb = mcolors.to_rgb(base_color)\n            # higher count = darker\n            shade_rgb = tuple(c * (0.4 + 0.6 * (1 - norm)) for c in base_rgb)\n            fill_color = mcolors.to_hex(shade_rgb)\n        else:\n            fill_color = base_color\n\n        return {\n            \"fillColor\": fill_color,\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.6,\n        }\n\n    # ---- GeoJson with hover ----\n    folium.GeoJson(\n        neighborhoods,\n        name=\"Neighborhood Requests\",\n        style_function=style_function,\n        tooltip=folium.GeoJsonTooltip(\n            fields=[council_col, neighborhood_col, value_col],\n            aliases=[\n                \"Council District:\",\n                \"Neighborhood:\",\n                \"Request Count:\",\n            ],\n            localize=True,\n            sticky=True,\n        ),\n    ).add_to(m)\n\n    return m"},"outputs":[],"source":"# Display a chloropleth map to show num of service requests \n# for each neighborhood and council district\ndef neighborhood_choropleth_map(\n    neighborhoods_gdf: gpd.GeoDataFrame,\n    value_col: str = \"request_count\",\n    council_col: str = \"council_district\",\n    neighborhood_col: str = \"neighborhood_name\",\n    start_zoom: int = 12,\n    title: str = None,\n    subtitle: str = None\n):\n    \"\"\"\n    Display a choropleth map of neighborhoods colored by council district,\n    with shading based on request count and hover tooltips.\n    Optional fixed title and subtitle in the top-left corner.\n\n    Args:\n        neighborhoods_gdf: Neighborhood polygons with request counts (GeoDataFrame)\n        value_col: Column with aggregated request counts (string)\n        council_col: Council district column (str)\n        neighborhood_col: Neighborhood name column (str)\n        start_zoom: Initial zoom level (int)\n        title: Optional map title (str)\n        subtitle: Optional map subtitle (str)\n\n    Returns:\n        folium.Map\n    \"\"\"\n\n    # ---- CRS normalization ----\n    neighborhoods = neighborhoods_gdf.to_crs(epsg=4326)\n\n    # ---- Fill missing values with 0 to include neighborhoods with no requests ----\n    neighborhoods[value_col] = neighborhoods[value_col].fillna(0)\n\n    # ---- Map center ----\n    center_lat = neighborhoods.geometry.centroid.y.mean()\n    center_lon = neighborhoods.geometry.centroid.x.mean()\n    m = folium.Map(location=[center_lat, center_lon], zoom_start=start_zoom)\n\n    # ---- Add fixed top-left title/subtitle ----\n    if title or subtitle:\n        html_content = \"\"\n        if title:\n            html_content += f\"<h4 style='margin:0'>{title}</h4>\"\n        if subtitle:\n            html_content += f\"<p style='margin:0'>{subtitle}</p>\"\n\n        template = f\"\"\"\n        <div style=\"\n            position: fixed;\n            top: 10px;\n            left: 10px;\n            z-index: 9999;\n            background-color: rgba(255,255,255,0.85);\n            padding: 5px 10px;\n            border-radius: 5px;\n            font-family: sans-serif;\n        \">\n            {html_content}\n        </div>\n        \"\"\"\n        macro = MacroElement()\n        macro._template = Template(template)\n        m.get_root().add_child(macro)\n\n    # ---- Council district base colors ----\n    unique_vals = neighborhoods[council_col].dropna().unique()\n    num_colors = len(unique_vals)\n    cmap = cmo.phase\n    colors = [\n        mcolors.rgb2hex(cmap(i / max(num_colors - 1, 1)))\n        for i in range(num_colors)\n    ]\n    council_color_map = {val: colors[i] for i, val in enumerate(unique_vals)}\n\n    # ---- Normalize request counts for shading ----\n    vmin = neighborhoods[value_col].min()\n    vmax = neighborhoods[value_col].max()\n\n    def style_function(feature):\n        props = feature[\"properties\"]\n        council = props.get(council_col)\n        count = props.get(value_col)\n\n        base_color = council_color_map.get(council, \"#cccccc\")\n\n        if count is not None and vmax > vmin:\n            norm = (count - vmin) / (vmax - vmin)\n            base_rgb = mcolors.to_rgb(base_color)\n            # higher count = darker\n            shade_rgb = tuple(c * (0.4 + 0.6 * (1 - norm)) for c in base_rgb)\n            fill_color = mcolors.to_hex(shade_rgb)\n        else:\n            fill_color = base_color\n\n        return {\n            \"fillColor\": fill_color,\n            \"color\": \"black\",\n            \"weight\": 0.5,\n            \"fillOpacity\": 0.6,\n        }\n\n    # ---- GeoJson with hover ----\n    folium.GeoJson(\n        neighborhoods,\n        name=\"Neighborhood Requests\",\n        style_function=style_function,\n        tooltip=folium.GeoJsonTooltip(\n            fields=[council_col, neighborhood_col, value_col],\n            aliases=[\n                \"Council District:\",\n                \"Neighborhood:\",\n                \"Request Count:\",\n            ],\n            localize=True,\n            sticky=True,\n        ),\n    ).add_to(m)\n\n    return m"},{"block_group":"93522ad37d56411fa5d41d05f291fa2d","cell_type":"code","execution_count":null,"metadata":{"cell_id":"29bafdc4123243c59843e3d7a68d786a","deepnote_block_group":"93522ad37d56411fa5d41d05f291fa2d","deepnote_cell_type":"code","deepnote_sorting_key":"13","deepnote_source":"# Calculate the average points_per_square_mile \n# and the min/max points_per_square_mile per council district\n\ndef council_district_stats(neighborhood_density_df, \n                           council_col=None, \n                           neighborhood_col=None,  \n                           density_col='points_per_sq_mile',\n                           points_col='points'):\n    \"\"\"\n    Calculate higher-level district statistics of points per square mile\n    (council districts, neighborhood clusters, etc.).\n\n    Parameters\n    ----------\n    neighborhood_density_df : pd.DataFrame\n        Neighborhood-level density with columns for neighborhood, density, and higher-level grouping.\n    council_col : str\n        Column name for higher-level grouping (e.g., council_district, neighborhood_cluster).\n    neighborhood_col : str\n        Column name for neighborhood in the DataFrame.\n    density_col : str\n        Column name for points per square mile.\n    points_col : str\n        Column name for total points in the neighborhood.\n\n    Returns\n    -------\n    pd.DataFrame\n        District-level stats: average, min, max density and neighborhoods corresponding to min/max.\n    \"\"\"\n    # Validate input columns exist\n    for col in [council_col, neighborhood_col, density_col, points_col]:\n        if col not in neighborhood_density_df.columns:\n            raise ValueError(f\"Column '{col}' not found in DataFrame. Available columns: {neighborhood_density_df.columns.tolist()}\")\n\n    # Group by the higher-level district and calculate mean/min/max densities\n    council_stats = (\n        neighborhood_density_df\n        .groupby(council_col)[density_col]\n        .agg(\n            avg_points_per_sq_mile='mean',\n            min_points_per_sq_mile='min',\n            max_points_per_sq_mile='max'\n        )\n        .round(1)\n        .reset_index()\n    )\n\n    # Total points per district\n    total_points = neighborhood_density_df.groupby(council_col)[points_col].sum().reset_index(name='total_points')\n    council_stats = council_stats.merge(total_points, on=council_col)\n\n    # Find neighborhoods corresponding to min and max densities\n    min_neighborhoods = neighborhood_density_df.groupby(council_col).apply(\n        lambda df: ', '.join(df.loc[df[density_col] == df[density_col].min(), neighborhood_col])\n    ).reset_index(name='min_neighborhood')\n\n    max_neighborhoods = neighborhood_density_df.groupby(council_col).apply(\n        lambda df: ', '.join(df.loc[df[density_col] == df[density_col].max(), neighborhood_col])\n    ).reset_index(name='max_neighborhood')\n\n    council_stats = council_stats.merge(min_neighborhoods, on = council_col)\n    council_stats = council_stats.merge(max_neighborhoods, on = council_col)\n\n    # Sort by average density descending\n    council_stats = council_stats.sort_values('avg_points_per_sq_mile', ascending = False).reset_index(drop = True)\n\n    return council_stats"},"outputs":[],"source":"# Calculate the average points_per_square_mile \n# and the min/max points_per_square_mile per council district\n\ndef council_district_stats(neighborhood_density_df, \n                           council_col=None, \n                           neighborhood_col=None,  \n                           density_col='points_per_sq_mile',\n                           points_col='points'):\n    \"\"\"\n    Calculate higher-level district statistics of points per square mile\n    (council districts, neighborhood clusters, etc.).\n\n    Parameters\n    ----------\n    neighborhood_density_df : pd.DataFrame\n        Neighborhood-level density with columns for neighborhood, density, and higher-level grouping.\n    council_col : str\n        Column name for higher-level grouping (e.g., council_district, neighborhood_cluster).\n    neighborhood_col : str\n        Column name for neighborhood in the DataFrame.\n    density_col : str\n        Column name for points per square mile.\n    points_col : str\n        Column name for total points in the neighborhood.\n\n    Returns\n    -------\n    pd.DataFrame\n        District-level stats: average, min, max density and neighborhoods corresponding to min/max.\n    \"\"\"\n    # Validate input columns exist\n    for col in [council_col, neighborhood_col, density_col, points_col]:\n        if col not in neighborhood_density_df.columns:\n            raise ValueError(f\"Column '{col}' not found in DataFrame. Available columns: {neighborhood_density_df.columns.tolist()}\")\n\n    # Group by the higher-level district and calculate mean/min/max densities\n    council_stats = (\n        neighborhood_density_df\n        .groupby(council_col)[density_col]\n        .agg(\n            avg_points_per_sq_mile='mean',\n            min_points_per_sq_mile='min',\n            max_points_per_sq_mile='max'\n        )\n        .round(1)\n        .reset_index()\n    )\n\n    # Total points per district\n    total_points = neighborhood_density_df.groupby(council_col)[points_col].sum().reset_index(name='total_points')\n    council_stats = council_stats.merge(total_points, on=council_col)\n\n    # Find neighborhoods corresponding to min and max densities\n    min_neighborhoods = neighborhood_density_df.groupby(council_col).apply(\n        lambda df: ', '.join(df.loc[df[density_col] == df[density_col].min(), neighborhood_col])\n    ).reset_index(name='min_neighborhood')\n\n    max_neighborhoods = neighborhood_density_df.groupby(council_col).apply(\n        lambda df: ', '.join(df.loc[df[density_col] == df[density_col].max(), neighborhood_col])\n    ).reset_index(name='max_neighborhood')\n\n    council_stats = council_stats.merge(min_neighborhoods, on = council_col)\n    council_stats = council_stats.merge(max_neighborhoods, on = council_col)\n\n    # Sort by average density descending\n    council_stats = council_stats.sort_values('avg_points_per_sq_mile', ascending = False).reset_index(drop = True)\n\n    return council_stats"},{"block_group":"4e12fd5f7ed64a099fa549831f126380","cell_type":"code","execution_count":null,"metadata":{"cell_id":"4af660d03dbd4dbeb4aa9554fbb67fef","deepnote_block_group":"4e12fd5f7ed64a099fa549831f126380","deepnote_cell_type":"code","deepnote_sorting_key":"14","deepnote_source":"def calculate_district_imu(\n    current_neighborhoods_gdf,\n    medically_underserved_gdf,\n    district_col = \"council_district\",\n    neighborhood_col = \"neighborhood_name\",\n    imu_col = \"med_underserv_ranking\",\n    non_residential_names = None,\n    fallback_value = 70\n):\n\n\n    # Filter out non-residential neighborhoods\n    if non_residential_names is not None:\n        residential_neighborhoods_gdf = current_neighborhoods_gdf[\n            ~current_neighborhoods_gdf[neighborhood_col].isin(non_residential_names)\n        ].copy()\n\n    neighborhoods_proj = residential_neighborhoods_gdf.to_crs(epsg=3857)\n    imu_proj = medically_underserved_gdf.to_crs(epsg=3857)\n\n    # Spatial join\n    joined = gpd.sjoin(\n        neighborhoods_proj,\n        imu_proj,\n        how=\"left\",\n        predicate=\"intersects\"\n    )\n\n    # Aggregate IMU at neighborhood level (take min if multiple overlaps)\n    neighborhood_imu = (\n        joined.groupby([neighborhood_col, district_col, \"geometry\"])\n        [imu_col]\n        .min()  # could also use .mean() if desired\n        .reset_index()\n    )\n\n    # Make it a GeoDataFrame so we can compute area\n    neighborhood_imu = gpd.GeoDataFrame(\n        neighborhood_imu, geometry=\"geometry\", crs=residential_neighborhoods_gdf.crs\n    )\n\n    # Assign fallback IMU\n    neighborhood_imu[imu_col] = neighborhood_imu[imu_col].fillna(fallback_value)\n\n    # Compute area and weighted IMU\n    neighborhood_imu[\"area_sq_mi\"] = neighborhood_imu.geometry.area / 2_589_988.11\n    neighborhood_imu[\"weighted_imu\"] = neighborhood_imu[imu_col] * neighborhood_imu[\"area_sq_mi\"]\n\n    # Aggregate by district\n    district_agg = (\n        neighborhood_imu\n        .groupby(district_col)\n        .agg(\n            total_weighted_imu=(\"weighted_imu\", \"sum\"),\n            total_area=(\"area_sq_mi\", \"sum\")\n        )\n        .reset_index()\n    )\n    district_agg[\"area_weighted_IMU\"] = (district_agg[\"total_weighted_imu\"] / district_agg[\"total_area\"]).round(0).astype(int)\n\n    # Find lowest-ranked neighborhood per district\n    min_neighborhood = (\n        neighborhood_imu.groupby(district_col)\n        .apply(lambda x: x.loc[x[imu_col].idxmin(), [neighborhood_col, imu_col]])\n        .reset_index()\n        .rename(columns={\n            neighborhood_col: \"lowest_ranked_neighborhood\",\n            imu_col: \"lowest_neighborhood_IMU\"\n        })\n    )\n\n    # Merge and sort\n    district_results = district_agg.merge(min_neighborhood, on=district_col)\n    district_results = district_results.sort_values(\"area_weighted_IMU\").reset_index(drop=True)\n\n    return district_results[\n        [district_col, \"area_weighted_IMU\", \"lowest_ranked_neighborhood\", \"lowest_neighborhood_IMU\"]\n    ]\n"},"outputs":[],"source":"def calculate_district_imu(\n    current_neighborhoods_gdf,\n    medically_underserved_gdf,\n    district_col = \"council_district\",\n    neighborhood_col = \"neighborhood_name\",\n    imu_col = \"med_underserv_ranking\",\n    non_residential_names = None,\n    fallback_value = 70\n):\n\n\n    # Filter out non-residential neighborhoods\n    if non_residential_names is not None:\n        residential_neighborhoods_gdf = current_neighborhoods_gdf[\n            ~current_neighborhoods_gdf[neighborhood_col].isin(non_residential_names)\n        ].copy()\n\n    neighborhoods_proj = residential_neighborhoods_gdf.to_crs(epsg=3857)\n    imu_proj = medically_underserved_gdf.to_crs(epsg=3857)\n\n    # Spatial join\n    joined = gpd.sjoin(\n        neighborhoods_proj,\n        imu_proj,\n        how=\"left\",\n        predicate=\"intersects\"\n    )\n\n    # Aggregate IMU at neighborhood level (take min if multiple overlaps)\n    neighborhood_imu = (\n        joined.groupby([neighborhood_col, district_col, \"geometry\"])\n        [imu_col]\n        .min()  # could also use .mean() if desired\n        .reset_index()\n    )\n\n    # Make it a GeoDataFrame so we can compute area\n    neighborhood_imu = gpd.GeoDataFrame(\n        neighborhood_imu, geometry=\"geometry\", crs=residential_neighborhoods_gdf.crs\n    )\n\n    # Assign fallback IMU\n    neighborhood_imu[imu_col] = neighborhood_imu[imu_col].fillna(fallback_value)\n\n    # Compute area and weighted IMU\n    neighborhood_imu[\"area_sq_mi\"] = neighborhood_imu.geometry.area / 2_589_988.11\n    neighborhood_imu[\"weighted_imu\"] = neighborhood_imu[imu_col] * neighborhood_imu[\"area_sq_mi\"]\n\n    # Aggregate by district\n    district_agg = (\n        neighborhood_imu\n        .groupby(district_col)\n        .agg(\n            total_weighted_imu=(\"weighted_imu\", \"sum\"),\n            total_area=(\"area_sq_mi\", \"sum\")\n        )\n        .reset_index()\n    )\n    district_agg[\"area_weighted_IMU\"] = (district_agg[\"total_weighted_imu\"] / district_agg[\"total_area\"]).round(0).astype(int)\n\n    # Find lowest-ranked neighborhood per district\n    min_neighborhood = (\n        neighborhood_imu.groupby(district_col)\n        .apply(lambda x: x.loc[x[imu_col].idxmin(), [neighborhood_col, imu_col]])\n        .reset_index()\n        .rename(columns={\n            neighborhood_col: \"lowest_ranked_neighborhood\",\n            imu_col: \"lowest_neighborhood_IMU\"\n        })\n    )\n\n    # Merge and sort\n    district_results = district_agg.merge(min_neighborhood, on=district_col)\n    district_results = district_results.sort_values(\"area_weighted_IMU\").reset_index(drop=True)\n\n    return district_results[\n        [district_col, \"area_weighted_IMU\", \"lowest_ranked_neighborhood\", \"lowest_neighborhood_IMU\"]\n    ]\n"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=eebef062-1e8d-49a7-8fcf-4600030c2568' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' />\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"metadata":{"deepnote_notebook_id":"363f4363bd044743a796525c4b8f275b","deepnote_notebook_name":"Functions Module"},"nbformat":4,"nbformat_minor":0}